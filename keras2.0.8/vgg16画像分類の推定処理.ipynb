{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vgg16画像分類の推定処理.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"WW4WwEMNHU6M","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":2}],"base_uri":"https://localhost:8080/","height":348},"outputId":"6559a24c-71d5-4708-91f5-271613194460","executionInfo":{"status":"ok","timestamp":1520856576850,"user_tz":-540,"elapsed":3926,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["!pip install Keras==2.0.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: Keras==2.0.0 in /usr/local/lib/python3.6/dist-packages\r\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.0)\r\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.0)\r\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.0)\r\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\r\n","Requirement already satisfied: tensorboard<1.7.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\r\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\r\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\r\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\r\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\r\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.4.0->tensorflow->Keras==2.0.0)\n"],"name":"stdout"}]},{"metadata":{"id":"hFmy5bWkHXZL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"b181321e-07c9-4e81-b4be-9eda5b6a1ef3","executionInfo":{"status":"ok","timestamp":1520856588094,"user_tz":-540,"elapsed":1315,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["import numpy as np\n","import warnings\n","\n","from keras.models import Model\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Input\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import GlobalMaxPooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras.preprocessing import image\n","from keras.utils import layer_utils\n","from keras.utils.data_utils import get_file\n","from keras import backend as K\n","from keras.applications.imagenet_utils import decode_predictions\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.applications.imagenet_utils import _obtain_input_shape\n","from keras.engine.topology import get_source_inputs"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"DnFzaL9oHdnn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":8}],"base_uri":"https://localhost:8080/","height":293},"outputId":"46c1dde4-b796-493a-9516-9e2b25e25567","executionInfo":{"status":"ok","timestamp":1520856684333,"user_tz":-540,"elapsed":3511,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n","WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","!wget https://www.dropbox.com/s/mmatzj3k5cj5rak/Horton-the-Elephant.png"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2018-03-12 12:11:22--  https://www.dropbox.com/s/mmatzj3k5cj5rak/Horton-the-Elephant.png\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.1, 2620:100:601c:1::a27d:601\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://dl.dropboxusercontent.com/content_link/FkCY3lYogPvQOOHujeh7m9Nl5CYwGpEXeJ1tAt9lVanVGaFiBhvHeYrRIljIfCyB/file [following]\n","--2018-03-12 12:11:23--  https://dl.dropboxusercontent.com/content_link/FkCY3lYogPvQOOHujeh7m9Nl5CYwGpEXeJ1tAt9lVanVGaFiBhvHeYrRIljIfCyB/file\n","Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.6.6, 2620:100:601b:6::a27d:806\n","Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.6.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1580732 (1.5M) [image/png]\n","Saving to: ‘Horton-the-Elephant.png.1’\n","\n","Horton-the-Elephant 100%[===================>]   1.51M  --.-KB/s    in 0.08s   \n","\n","2018-03-12 12:11:24 (20.1 MB/s) - ‘Horton-the-Elephant.png.1’ saved [1580732/1580732]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"UdqzpYiGHf8f","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def VGG16(include_top=True, weights='imagenet',\n","          input_tensor=None, input_shape=None,\n","          pooling=None,\n","          classes=1000):\n","\n","    if weights not in {'imagenet', None}:\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization) or `imagenet` '\n","                         '(pre-training on ImageNet).')\n","\n","    if weights == 'imagenet' and include_top and classes != 1000:\n","        raise ValueError('If using `weights` as imagenet with `include_top`'\n","                         ' as true, `classes` should be 1000')\n","    # Determine proper input shape\n","    input_shape = _obtain_input_shape(input_shape,\n","                                      default_size=224,\n","                                      min_size=48,\n","                                      data_format=K.image_data_format(),\n","                                      include_top=include_top)\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","    # Block 1\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # Block 2\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","    # Block 3\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","    # Block 4\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","    # Block 5\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","\n","    if include_top:\n","        # Classification block\n","        x = Flatten(name='flatten')(x)\n","        x = Dense(4096, activation='relu', name='fc1')(x)\n","        x = Dense(4096, activation='relu', name='fc2')(x)\n","        x = Dense(classes, activation='softmax', name='predictions')(x)\n","    else:\n","        if pooling == 'avg':\n","            x = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            x = GlobalMaxPooling2D()(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","    # Create model.\n","    model = Model(inputs, x, name='vgg16')\n","\n","    # load weights\n","    if weights == 'imagenet':\n","        if include_top:\n","            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n","                                    WEIGHTS_PATH,\n","                                    cache_subdir='models')\n","        else:\n","            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","                                    WEIGHTS_PATH_NO_TOP,\n","                                    cache_subdir='models')\n","        model.load_weights(weights_path)\n","        if K.backend() == 'theano':\n","            layer_utils.convert_all_kernels_in_model(model)\n","\n","        if K.image_data_format() == 'channels_first':\n","            if include_top:\n","                maxpool = model.get_layer(name='block5_pool')\n","                shape = maxpool.output_shape[1:]\n","                dense = model.get_layer(name='fc1')\n","                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n","\n","            if K.backend() == 'tensorflow':\n","                warnings.warn('You are using the TensorFlow backend, yet you '\n","                              'are using the Theano '\n","                              'image data format convention '\n","                              '(`image_data_format=\"channels_first\"`). '\n","                              'For best performance, set '\n","                              '`image_data_format=\"channels_last\"` in '\n","                              'your Keras config '\n","                              'at ~/.keras/keras.json.')\n","    return model\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ICeTsdZOHtMg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":3}],"base_uri":"https://localhost:8080/","height":89},"outputId":"fbf77046-9c0b-4d84-ae65-7d88645ee9e0","executionInfo":{"status":"ok","timestamp":1520856698465,"user_tz":-540,"elapsed":3533,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["if __name__ == '__main__':\n","    model = VGG16(include_top=True, weights='imagenet')\n","\n","    img_path = 'Horton-the-Elephant.png'\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    print('Input image shape:', x.shape)\n","\n","    preds = model.predict(x)\n","    print('Predicted:', decode_predictions(preds))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Input image shape: (1, 224, 224, 3)\n","Downloading data from https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n","Predicted: [[('n02808440', 'bathtub', 0.08004384), ('n02113978', 'Mexican_hairless', 0.07693007), ('n04493381', 'tub', 0.070641264), ('n02124075', 'Egyptian_cat', 0.05616565), ('n03255030', 'dumbbell', 0.041161817)]]\n"],"name":"stdout"}]},{"metadata":{"id":"lrP54ypgHv4O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":69},"outputId":"3e517b36-55c2-4451-9b6c-b9649b617e91","executionInfo":{"status":"ok","timestamp":1520856810078,"user_tz":-540,"elapsed":1521,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["!ls"],"execution_count":8,"outputs":[{"output_type":"stream","text":["datalab\t\t\t Horton-the-Elephant.png.1  __pycache__\r\n","deep-learning-models\t imagenet_utils.py\t    resnet50.py\r\n","Horton-the-Elephant.png  predictions.csv\t    vgg16.py\r\n"],"name":"stdout"}]},{"metadata":{"id":"L7zo_Gr6ITwu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1},{"item_id":2}],"base_uri":"https://localhost:8080/","height":52},"outputId":"3732c70d-aab0-4560-f05f-f7c921f0a327","executionInfo":{"status":"ok","timestamp":1522135171828,"user_tz":-540,"elapsed":1180,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras import backend as K\n","print(K.image_data_format())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["channels_last\n"],"name":"stdout"}]},{"metadata":{"id":"4urgRTkcUzPp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}