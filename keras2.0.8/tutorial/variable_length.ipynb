{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"variable_length.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"RFltTtObpZ1A","colab_type":"text"},"cell_type":"markdown","source":["# 入力を可変長にしたいのじゃ"]},{"metadata":{"id":"RHoSwL9ppeLL","colab_type":"text"},"cell_type":"markdown","source":["\n","GlobalAveragePooling2Dあるいは\n","\n","SPP(Spatial Pyramid Pooling)使えば？とガチな人にアドバイスされ使ってみた\n","https://github.com/yhenon/keras-spp\n","\n","\n","参考\n","\n","Variable-size image to convolutional layer\n","\n","https://github.com/keras-team/keras/issues/1920\n","\n","What is the advantage of using an InputLayer (or an Input) in a Keras model with Tensorflow tensors?\n","\n","https://stackoverflow.com/questions/45217973/what-is-the-advantage-of-using-an-inputlayer-or-an-input-in-a-keras-model-with/45259874\n","\n","How to give variable size images as input in keras\n","\n","https://stackoverflow.com/questions/47795697/how-to-give-variable-size-images-as-input-in-keras\n","\n"]},{"metadata":{"id":"arUqLnKNfgVB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"c222e718-31a1-4952-c442-312c3265049e","executionInfo":{"status":"ok","timestamp":1524888146197,"user_tz":-540,"elapsed":7831,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import keras\n","keras.__version__"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.1.6'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"oBabtIzGhVuq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"de667d12-a5ce-45d7-df71-81619de9f4b1","executionInfo":{"status":"ok","timestamp":1524888146783,"user_tz":-540,"elapsed":544,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import keras.backend as K\n","print(K.image_dim_ordering())\n","print(K.image_data_format())\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tf\n","channels_last\n"],"name":"stdout"}]},{"metadata":{"id":"7NHbhdBOehPy","colab_type":"text"},"cell_type":"markdown","source":["# 普通のサンプル"]},{"metadata":{"id":"9jPn7_2DeAqr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":67},"outputId":"7964875c-0c6e-4d03-8062-5c0eda393e19","executionInfo":{"status":"ok","timestamp":1524888253242,"user_tz":-540,"elapsed":1895,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, ZeroPadding2D\n","from keras.layers import Input, Dense, Dropout, Activation\n","from keras.models import Sequential\n","from keras.models import Model\n","\n","model = Sequential()\n","model.add(Dense(32, activation='relu', input_dim=100))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# ダミーデータの作成\n","import numpy as np\n","data = np.random.random((1000, 100))\n","labels = np.random.randint(2, size=(1000, 1))\n","\n","model.fit(data, labels, epochs=1, batch_size=32)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Epoch 1/1\n","1000/1000 [==============================] - 1s 1ms/step - loss: 0.7073 - acc: 0.4870\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa0838d1e48>"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"ggnK3j9xetc-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n","# from keras.layers import Input, Dense, Dropout, Activation\n","# from keras.models import Sequential\n","# from keras.models import Model\n","\n","\n","# model = Sequential()\n","# model.add(Dense(32, activation='relu', input_dim=(None)))\n","# model.add(Dense(1, activation='sigmoid'))\n","# model.compile(optimizer='rmsprop',\n","#               loss='binary_crossentropy',\n","#               metrics=['accuracy'])\n","\n","# # ダミーデータの作成\n","# import numpy as np\n","# data = np.random.random((1000, 100))\n","# labels = np.random.randint(2, size=(1000, 1))\n","\n","# model.fit(data, labels, epochs=1, batch_size=32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O65EiBmnfHWt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, ZeroPadding2D\n","# from sklearn.metrics import mean_squared_error\n","# def test():\n","#     tr = False\n","#     model = Sequential()\n","#     model.add(ZeroPadding2D((3,3),input_shape=(None,None,3), name='layer_0'))\n","#     model.add(Conv2D(64, (3, 3), activation='relu', trainable=tr))\n","#     model.add(ZeroPadding2D((1,1)))\n","#     model.add(Conv2D(64, (3, 3), activation='relu', trainable=tr))\n","#     model.add(MaxPooling2D((2,2), strides=(2,2)))\n","#     model.add(SpatialPyramidPooling([1,2,4]))\n","#     model.add(Dense(2, activation='softmax'))    \n","#     model.compile(loss=mean_squared_error, optimizer='adam')\n","#     return model\n","\n","# t = test()\n","# t.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EQd9l7CnjHOo","colab_type":"text"},"cell_type":"markdown","source":["# SpatialPyramidPooling"]},{"metadata":{"id":"l3RKg6nTggYY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":101},"outputId":"8c2e449a-d065-436e-f332-0fea2c34d8e9","executionInfo":{"status":"ok","timestamp":1524856147629,"user_tz":-540,"elapsed":4482,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["# !git clone https://github.com/yhenon/keras-spp.git\n","# !cp -R keras-spp/spp spp\n","# !ls spp"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Cloning into 'keras-spp'...\n","remote: Counting objects: 125, done.\u001b[K\n","remote: Total 125 (delta 0), reused 0 (delta 0), pack-reused 125\u001b[K\n","Receiving objects: 100% (125/125), 29.25 KiB | 2.66 MiB/s, done.\n","Resolving deltas: 100% (76/76), done.\n"],"name":"stdout"}]},{"metadata":{"id":"tF4aycasgQvL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":222},"outputId":"8d49a656-3c45-4f54-e210-baac773f5631","executionInfo":{"status":"ok","timestamp":1524856490899,"user_tz":-540,"elapsed":3586,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Conv2D, Activation, MaxPooling2D, Dense\n","from spp.SpatialPyramidPooling import SpatialPyramidPooling\n","\n","batch_size = 64\n","num_channels = 3\n","num_classes = 10\n","\n","model = Sequential()\n","\n","# uses theano ordering. Note that we leave the image size as None to allow multiple image sizes\n","model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=(None, None, 3)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, 3, 3))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(64, 3, 3, border_mode='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, 3, 3))\n","model.add(Activation('relu'))\n","model.add(SpatialPyramidPooling([1, 2, 4]))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='sgd')\n","\n","# train on 64x64x3 images\n","model.fit(np.random.rand(batch_size, 64, 64, num_channels), np.zeros((batch_size, num_classes)))\n","# train on 32x32x3 images\n","model.fit(np.random.rand(batch_size, 32, 32, num_channels), np.zeros((batch_size, num_classes)))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(None, Non..., padding=\"same\")`\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","64/64 [==============================] - 2s 26ms/step - loss: 0.0000e+00\n","Epoch 1/1\n","64/64 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fea2bf57710>"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"uXOoPyiMgkW4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"YcWnb8zjYkKA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":590},"outputId":"460a186a-3648-470e-d39b-da9fc3b4a1f4","executionInfo":{"status":"error","timestamp":1524855247377,"user_tz":-540,"elapsed":622,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n","from keras.layers import Input, Dense, Dropout, Activation\n","from keras.models import Model\n","\n","nr_channels = 3\n","input_layer = Input(shape=(None, None, nr_channels))\n","#filters, kernel_size, strides=(1, 1),,,,\n","x = Conv2D(16,(4,4), activation = 'elu')(input_layer)  # single stride 4x4 filter for 16 maps\n","x = Conv2D(32,(4,4), activation = 'elu')(x)         # single stride 4x4 filter for 32 maps\n","x = Dropout(0.5)(x)\n","x = Conv2D(64,(4,4), activation = 'elu')(x)         # single stride 4x4 filter for 64 maps\n","x = Dropout(0.5)(x)\n","x = Conv2D(128, (1,1))(x)                           # finally 128 maps for global average-pool\n","x = GlobalAveragePooling2D()(x)                     # pseudo-dense 128 layer\n","output_layer = Dense(10, activation = \"softmax\")(x) # softmax output\n","model = Model(inputs = input_layer, outputs=output_layer)\n","model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","x_train = np.random.random((1000, 4, 4, 1))\n","y_train = np.random.random((1000, 2))\n","\n","model.fit(x_train, y_train, batch_size=200, nb_epoch=1, shuffle=False, verbose=1)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-8cee78eeaf4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_12 to have shape (None, None, 3) but got array with shape (4, 4, 1)"]}]},{"metadata":{"id":"L-HDESGSXBsv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SU3O04JMWyho","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from keras.layers import InputLayer\n","\n","a = tf.placeholder(dtype=tf.float32, shape=(None, 784))\n","\n","model = Sequential()\n","model.add(InputLayer(input_tensor=a, input_shape=(None, 784)))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","\n","output = model.output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K_HKJugnYkQM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# from keras.models import Sequential\n","# from keras.layers import LSTM, Dense\n","# import numpy as np\n","# from keras import backend as K\n","\n","# model = Sequential()\n","# model.add(Dense(32, input_dim=(None)))\n","# model.add(Activation('relu'))\n","\n","# x_train = np.random.random((1000, 50))\n","# y_train = np.random.random((1000, 2))\n","\n","# model.fit(x_train, y_train, batch_size=200, nb_epoch=1, shuffle=False, verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sMc6D8-mXZ8u","colab_type":"text"},"cell_type":"markdown","source":["# Variable length sequence for RNN"]},{"metadata":{"id":"9Y8_haRMXzME","colab_type":"text"},"cell_type":"markdown","source":["LSTMはinput_shape=(None, 100)のように入力次元を可変にできる。"]},{"metadata":{"id":"ODrQt0zyXad7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":587},"outputId":"2ce9d397-1b2f-477e-d407-591a54bd7f3f","executionInfo":{"status":"error","timestamp":1524855589373,"user_tz":-540,"elapsed":614,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","import numpy as np\n","from keras import backend as K\n","\n","with K.get_session():\n","\n","    # create model\n","    model = Sequential()\n","    model.add(LSTM(100, return_sequences=True, stateful=True, input_shape=(None, 100),\n","             batch_input_shape=(200, None, 100)))\n","    model.add(LSTM(100))\n","    model.add(Dense(2, activation='softmax'))\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer='rmsprop',\n","                  metrics=['accuracy'])\n","\n","    # Generate dummy training data\n","    x_train = np.random.random((1000, 50, 100))\n","    x_train_2 = np.random.random((1000, 10, 100))\n","    y_train = np.random.random((1000, 2))\n","    y_train_2 = np.random.random((1000, 2))\n","\n","    # Generate dummy validation data\n","    x_val = np.random.random((200, 50, 100))\n","    y_val = np.random.random((200, 2))\n","\n","    # fit and eval models\n","    model.fit(x_train, y_train, batch_size=200, nb_epoch=1, shuffle=False, validation_data=(x_val, y_val), verbose=1)\n","    model.fit(x_train_2, y_train_2, batch_size=200, nb_epoch=1, shuffle=False, validation_data=(x_val, y_val), verbose=1)\n","    score = model.evaluate(x_val, y_val, batch_size=200, verbose=1)"],"execution_count":26,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-48293d7eaa80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 193\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n","\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."]}]},{"metadata":{"id":"pbuJEmCwYBwx","colab_type":"text"},"cell_type":"markdown","source":["このNone手段を使用すると、バッチごとに異なるバッチサイズを設定できます。のfit_generator代わりに使用してくださいfit。1つのバッチは(1, 15, 100)、次のバッチは(1, 24, 100)どんなものでもよい。つまり、サイズ1のバッチを実行しているだけなので騒々しいですが、バッチごとに異なる長さのものを簡単に書くことができます。\n","\n","1つのバッチ内で異なる長さが必要な場合は、マスキングを使用する必要があります。インバンドまたはアウトオブバンドで信号を送ることができます。帯域内は、ステップを無視する必要があることを示す特別な値になります。帯域外は1、含まれているステップと0除外されたステップのための独立した入力となります。あなたの損失にマスクを掛けるので、除外されたステップの損失は0になります。\n","\n","上記の両方を行う場合、各バッチはそのバッチ内の最長シーケンスの長さになります。そのバッチ内のより短い配列は、パディングされマスクされる。これは、最も効率的な方法であり、毎回のデータ量が最小でなければなりません。\n","\n","両方を行うのが最善でしょう。あなたが使用するならばfit、最長のシーケンスの長さまですべてをパディングする必要があります。本当に長い外れ値がある場合、それは大きな影響を与えます。\n","\n","ここにはやや複雑な例がありますが、上記の方法の1つが含まれています。この実験は入力と出力を連結しているので、max(input len+output len)代わりに使用するだけmax(input)+max(output)ですが、それは概念実証であり、必要ではありません。\n","https://github.com/bstriner/keras-seq2seq\n","\n","一番きれいなコードではありませんが、それがどのように動作するかを理解していれば、あなたは何でもできるはずです。"]},{"metadata":{"id":"WHkLpk3_YTIj","colab_type":"text"},"cell_type":"markdown","source":["方法1および2は排他的ではない。1回だけ行うと、各バッチにシーケンスが1つしかないので、パディングは必要ありません。\n","\n","異なるバッチ間の状態は、通常保持されていないか関連性がありません。statefulケラスのオプションは、あなたが何をしているかを確かめない限り、私がお勧めするものではありません。statefulバッチ間の状態は保持されますが、バッチ間では逆戻りしません。したがって、前の状態を使用しますが、前の状態を有効にすることを学ぶことはできません。\n","\n","多くの人々statefulは、それが実際よりも多くのことを考えて問題にぶつかる。すべてのLSTMはステートフルでstatefulあり、バッチ間の状態のみであり、通常は悪い考えです。単一のバッチに収まらないような非常に長いシーケンスがある場合にのみ便利です。\n","\n","学習はバッチ内でのみ機能します。20ステップ離れた依存関係を学習する必要がある場合は、各バッチに少なくとも20ステップが必要です。あなたは10の2ステートフルバッチを行うことができますが、それは有用な何かを学ぶかどうかはランダムです。\n","\n","LSTMを訓練するための最も簡単で最良の方法は、多くの異なるサブシーケンスを取り、それらをすべてLSTMを通して実行することです（そうではありませんstateful）。そうすることで、シーケンス内のどこかで拾い上げることができるLSTMを学習しようとしていて、何か役に立つことができます。\n","\n","LSTMの初期状態は、学習されたものです。その初期状態は、バッチ内の各シーケンスについて同じです。あなたのすべての事例で効果的な初期状態を学習します。\n","\n","tldr; stateful正当な理由がない限り使用しないでください。それなしでトレーニングはより安定しています。\n","\n","機械学習は、意味のある方法で一般化できるものを学ぶことです。それを行う最良の方法は、多くの異なるサブシーケンスとそれらのすべてで機能するLSTMを持つことです。より多くの方法で、データをより細かくスライスしてダイスすることができます。\n","\n","極端な例として、茶色のコーパス全体を1つのバッチで1つのシーケンスとして訓練したLSTMを想像してみてください。それは学ぶだろうが、それは無意味だろう。コーパス内のどこからでも始まる可変長サブシーケンスを予測できるLSTMは、意味のある何かを学習することになります。\n","\n","https://github.com/keras-team/keras/issues/6776\n"]},{"metadata":{"id":"MytjMlnEXoP4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"FdT0dfTOksBi","colab_type":"text"},"cell_type":"markdown","source":["# 普通のCNN"]},{"metadata":{"id":"YeKyuSL4ltfJ","colab_type":"text"},"cell_type":"markdown","source":["mnistで動かす。"]},{"metadata":{"id":"Ed1CLRtZlG1h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1126},"outputId":"9cc90cba-4e88-43c0-8111-a87b0a522565","executionInfo":{"status":"ok","timestamp":1524890667769,"user_tz":-540,"elapsed":6215,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 30\n","img_rows, img_cols = 28, 28\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train[:500]\n","y_train = y_train[:500]\n","x_test = x_test[:500]\n","y_test = y_test[:500]\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":43,"outputs":[{"output_type":"stream","text":["x_train shape: (500, 28, 28, 1)\n","500 train samples\n","500 test samples\n","Train on 500 samples, validate on 500 samples\n","Epoch 1/30\n","500/500 [==============================] - 1s 2ms/step - loss: 2.1072 - acc: 0.2640 - val_loss: 1.8231 - val_acc: 0.4780\n","Epoch 2/30\n","500/500 [==============================] - 0s 280us/step - loss: 1.5162 - acc: 0.5680 - val_loss: 2.2483 - val_acc: 0.1820\n","Epoch 3/30\n","500/500 [==============================] - 0s 291us/step - loss: 1.3621 - acc: 0.5740 - val_loss: 0.9003 - val_acc: 0.7000\n","Epoch 4/30\n","500/500 [==============================] - 0s 279us/step - loss: 0.9819 - acc: 0.6880 - val_loss: 0.8088 - val_acc: 0.7580\n","Epoch 5/30\n","500/500 [==============================] - 0s 267us/step - loss: 0.6503 - acc: 0.8200 - val_loss: 0.6590 - val_acc: 0.7720\n","Epoch 6/30\n","500/500 [==============================] - 0s 269us/step - loss: 0.5769 - acc: 0.8040 - val_loss: 0.5499 - val_acc: 0.8440\n","Epoch 7/30\n","500/500 [==============================] - 0s 274us/step - loss: 0.4789 - acc: 0.8400 - val_loss: 0.5181 - val_acc: 0.8460\n","Epoch 8/30\n","500/500 [==============================] - 0s 265us/step - loss: 0.3682 - acc: 0.8800 - val_loss: 0.4668 - val_acc: 0.8420\n","Epoch 9/30\n","500/500 [==============================] - 0s 275us/step - loss: 0.3528 - acc: 0.8840 - val_loss: 0.4974 - val_acc: 0.8200\n","Epoch 10/30\n","500/500 [==============================] - 0s 274us/step - loss: 0.3176 - acc: 0.9140 - val_loss: 0.4354 - val_acc: 0.8660\n","Epoch 11/30\n","500/500 [==============================] - 0s 277us/step - loss: 0.2840 - acc: 0.9020 - val_loss: 0.4558 - val_acc: 0.8600\n","Epoch 12/30\n","500/500 [==============================] - 0s 283us/step - loss: 0.2360 - acc: 0.9280 - val_loss: 0.5339 - val_acc: 0.8280\n","Epoch 13/30\n","500/500 [==============================] - 0s 278us/step - loss: 0.2261 - acc: 0.9260 - val_loss: 0.4006 - val_acc: 0.8760\n","Epoch 14/30\n","500/500 [==============================] - 0s 257us/step - loss: 0.1645 - acc: 0.9660 - val_loss: 0.3690 - val_acc: 0.8920\n","Epoch 15/30\n","500/500 [==============================] - 0s 285us/step - loss: 0.1654 - acc: 0.9540 - val_loss: 0.3901 - val_acc: 0.8820\n","Epoch 16/30\n","500/500 [==============================] - 0s 261us/step - loss: 0.1582 - acc: 0.9560 - val_loss: 0.3721 - val_acc: 0.8880\n","Epoch 17/30\n","500/500 [==============================] - 0s 274us/step - loss: 0.1068 - acc: 0.9720 - val_loss: 0.3502 - val_acc: 0.9100\n","Epoch 18/30\n","500/500 [==============================] - 0s 257us/step - loss: 0.1135 - acc: 0.9680 - val_loss: 0.3649 - val_acc: 0.8900\n","Epoch 19/30\n","500/500 [==============================] - 0s 246us/step - loss: 0.1258 - acc: 0.9640 - val_loss: 0.3491 - val_acc: 0.9000\n","Epoch 20/30\n","500/500 [==============================] - 0s 264us/step - loss: 0.1054 - acc: 0.9640 - val_loss: 0.3836 - val_acc: 0.8780\n","Epoch 21/30\n","500/500 [==============================] - 0s 246us/step - loss: 0.1083 - acc: 0.9680 - val_loss: 0.4857 - val_acc: 0.8620\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 22/30\n","500/500 [==============================] - 0s 258us/step - loss: 0.1202 - acc: 0.9600 - val_loss: 0.3503 - val_acc: 0.8960\n","Epoch 23/30\n","500/500 [==============================] - 0s 256us/step - loss: 0.0778 - acc: 0.9780 - val_loss: 0.3618 - val_acc: 0.8960\n","Epoch 24/30\n","500/500 [==============================] - 0s 268us/step - loss: 0.0682 - acc: 0.9720 - val_loss: 0.3436 - val_acc: 0.9060\n","Epoch 25/30\n","500/500 [==============================] - 0s 247us/step - loss: 0.0585 - acc: 0.9780 - val_loss: 0.3470 - val_acc: 0.9000\n","Epoch 26/30\n","500/500 [==============================] - 0s 245us/step - loss: 0.0530 - acc: 0.9880 - val_loss: 0.4279 - val_acc: 0.8860\n","Epoch 27/30\n","500/500 [==============================] - 0s 240us/step - loss: 0.0484 - acc: 0.9840 - val_loss: 0.3561 - val_acc: 0.9100\n","Epoch 28/30\n","500/500 [==============================] - 0s 257us/step - loss: 0.0525 - acc: 0.9820 - val_loss: 0.3668 - val_acc: 0.9040\n","Epoch 29/30\n","500/500 [==============================] - 0s 245us/step - loss: 0.0484 - acc: 0.9880 - val_loss: 0.3084 - val_acc: 0.9040\n","Epoch 30/30\n","500/500 [==============================] - 0s 247us/step - loss: 0.0296 - acc: 0.9960 - val_loss: 0.3531 - val_acc: 0.9060\n","Test loss: 0.3531200523376465\n","Test accuracy: 0.9059999990463257\n"],"name":"stdout"}]},{"metadata":{"id":"JnbpqU-Qlv1-","colab_type":"text"},"cell_type":"markdown","source":["mnistをリサイズして可変の画像にする。"]},{"metadata":{"id":"HwQfX4bRbHwh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"5IeSXjxwiGSM","colab_type":"text"},"cell_type":"markdown","source":["## 可変長入力可能のモデルで30 30のmnistにする。"]},{"metadata":{"id":"9BowOcRGlzsb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":188},"outputId":"6faf03d6-f008-472f-d7a6-670cd982a14a","executionInfo":{"status":"ok","timestamp":1524890026899,"user_tz":-540,"elapsed":2282,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from __future__ import print_function\n","import cv2\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras import backend as K\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 1\n","img_rows, img_cols = 28, 28\n","input_width, input_height = None, None\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train[:500]\n","y_train = y_train[:500]\n","x_test = x_test[:500]\n","y_test = y_test[:500]\n","#cv2で30 30にリサイズ\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","#     in_layer = Input(shape=(1, None, None))\n","    input_shape = (1, input_width, input_height)\n","\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","#     in_layer = Input(shape=(None, None,1))\n","    input_shape = (input_width, input_height, 1)\n","\n","#28 28の画像から30 30に変換\n","x_train = np.array([cv2.resize(img[0] ,(30,30)).reshape(30,30,1) for img in x_train])\n","x_test = np.array([cv2.resize(img[0] ,(30,30)).reshape(30,30,1) for img in x_test])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), border_mode='same', activation='relu', input_shape=input_shape)) #input shape\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(GlobalAveragePooling2D())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":27,"outputs":[{"output_type":"stream","text":["x_train shape: (500, 30, 30, 1)\n","500 train samples\n","500 test samples\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(None, Non..., padding=\"same\")`\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 500 samples, validate on 500 samples\n","Epoch 1/1\n","500/500 [==============================] - 1s 1ms/step - loss: 2.3025 - acc: 0.1200 - val_loss: 2.3022 - val_acc: 0.1340\n","Test loss: 2.3022018394470214\n","Test accuracy: 0.13400000005960463\n"],"name":"stdout"}]},{"metadata":{"id":"9JeFzvQJktUT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"iJARp7rWiR3U","colab_type":"text"},"cell_type":"markdown","source":["## サイズを色々変えてみる"]},{"metadata":{"id":"xZWctMFid7Oa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import print_function\n","import cv2\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras import backend as K\n","\n","def init_data(image_width_size, image_height_size):\n","        num_classes = 10\n","        img_rows, img_cols = 28, 28\n","        input_width, input_height = None, None\n","        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","        x_train = x_train[:500]\n","        y_train = y_train[:500]\n","        x_test = x_test[:500]\n","        y_test = y_test[:500]\n","        #cv2で30 30にリサイズ\n","        if K.image_data_format() == 'channels_first':\n","            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","            input_shape = (1, input_width, input_height)\n","\n","        else:\n","            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","            input_shape = (input_width, input_height, 1)\n","\n","        #28 28の画像から任意サイズに変換\n","        x_train = np.array([cv2.resize(img[0] ,(image_width_size,image_height_size)).reshape(image_width_size,image_height_size,1) for img in x_train])\n","        x_test = np.array([cv2.resize(img[0] ,(image_width_size,image_height_size)).reshape(image_width_size,image_height_size,1) for img in x_test])\n","\n","        x_train = x_train.astype('float32')\n","        x_test = x_test.astype('float32')\n","        x_train /= 255\n","        x_test /= 255\n","        print('x_train shape:', x_train.shape)\n","        print(x_train.shape[0], 'train samples')\n","        print(x_test.shape[0], 'test samples')\n","\n","        y_train = keras.utils.to_categorical(y_train, num_classes)\n","        y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","def run_model(epochs = 100, batch_size = 128):  \n","        model = Sequential()\n","        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) #input shape\n","        model.add(Conv2D(64, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(0.25))\n","        model.add(GlobalAveragePooling2D())\n","        model.add(Dense(128, activation='relu'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(num_classes, activation='softmax'))\n","\n","        model.compile(loss=keras.losses.categorical_crossentropy,\n","                      optimizer=keras.optimizers.Adadelta(),\n","                      metrics=['accuracy'])\n","\n","        model.fit(x_train, y_train,\n","                  batch_size=batch_size,\n","                  epochs=epochs,\n","                  verbose=1,\n","                  validation_data=(x_test, y_test))\n","        score = model.evaluate(x_test, y_test, verbose=0)\n","        print('Test loss:', score[0])\n","        print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C5SXAPh3ivjr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":16938},"outputId":"131299c0-26cb-43e7-c3e4-60a8968f5e1c","executionInfo":{"status":"ok","timestamp":1524890915923,"user_tz":-540,"elapsed":56398,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["init_data(30,30)\n","run_model(epochs = 500)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["x_train shape: (500, 30, 30, 1)\n","500 train samples\n","500 test samples\n","Train on 500 samples, validate on 500 samples\n","Epoch 1/500\n","500/500 [==============================] - 1s 2ms/step - loss: 2.3072 - acc: 0.1060 - val_loss: 2.3018 - val_acc: 0.1340\n","Epoch 2/500\n","500/500 [==============================] - 0s 237us/step - loss: 2.3017 - acc: 0.1320 - val_loss: 2.2990 - val_acc: 0.1440\n","Epoch 3/500\n","500/500 [==============================] - 0s 241us/step - loss: 2.2973 - acc: 0.1480 - val_loss: 2.2973 - val_acc: 0.1400\n","Epoch 4/500\n","500/500 [==============================] - 0s 231us/step - loss: 2.2933 - acc: 0.1920 - val_loss: 2.2952 - val_acc: 0.2200\n","Epoch 5/500\n","500/500 [==============================] - 0s 229us/step - loss: 2.2913 - acc: 0.1640 - val_loss: 2.2937 - val_acc: 0.2040\n","Epoch 6/500\n","500/500 [==============================] - 0s 225us/step - loss: 2.2849 - acc: 0.1800 - val_loss: 2.2923 - val_acc: 0.2080\n","Epoch 7/500\n","500/500 [==============================] - 0s 237us/step - loss: 2.2795 - acc: 0.1480 - val_loss: 2.2888 - val_acc: 0.2200\n","Epoch 8/500\n","500/500 [==============================] - 0s 238us/step - loss: 2.2791 - acc: 0.1800 - val_loss: 2.2856 - val_acc: 0.2180\n","Epoch 9/500\n","500/500 [==============================] - 0s 227us/step - loss: 2.2759 - acc: 0.1680 - val_loss: 2.2826 - val_acc: 0.2100\n","Epoch 10/500\n","500/500 [==============================] - 0s 239us/step - loss: 2.2711 - acc: 0.2080 - val_loss: 2.2785 - val_acc: 0.2500\n","Epoch 11/500\n","500/500 [==============================] - 0s 223us/step - loss: 2.2674 - acc: 0.2100 - val_loss: 2.2732 - val_acc: 0.2180\n","Epoch 12/500\n","500/500 [==============================] - 0s 223us/step - loss: 2.2574 - acc: 0.1900 - val_loss: 2.2705 - val_acc: 0.2700\n","Epoch 13/500\n","500/500 [==============================] - 0s 225us/step - loss: 2.2542 - acc: 0.1760 - val_loss: 2.2585 - val_acc: 0.2480\n","Epoch 14/500\n","500/500 [==============================] - 0s 229us/step - loss: 2.2446 - acc: 0.1940 - val_loss: 2.2484 - val_acc: 0.2160\n","Epoch 15/500\n","500/500 [==============================] - 0s 215us/step - loss: 2.2264 - acc: 0.2340 - val_loss: 2.2380 - val_acc: 0.2160\n","Epoch 16/500\n","500/500 [==============================] - 0s 226us/step - loss: 2.2119 - acc: 0.2140 - val_loss: 2.2395 - val_acc: 0.1600\n","Epoch 17/500\n","500/500 [==============================] - 0s 215us/step - loss: 2.2076 - acc: 0.1860 - val_loss: 2.2133 - val_acc: 0.1860\n","Epoch 18/500\n","500/500 [==============================] - 0s 237us/step - loss: 2.1864 - acc: 0.2220 - val_loss: 2.1978 - val_acc: 0.1760\n","Epoch 19/500\n","500/500 [==============================] - 0s 224us/step - loss: 2.1926 - acc: 0.1960 - val_loss: 2.1884 - val_acc: 0.1740\n","Epoch 20/500\n","500/500 [==============================] - 0s 222us/step - loss: 2.2239 - acc: 0.1720 - val_loss: 2.1913 - val_acc: 0.1680\n","Epoch 21/500\n","500/500 [==============================] - 0s 212us/step - loss: 2.1382 - acc: 0.2400 - val_loss: 2.1433 - val_acc: 0.2160\n","Epoch 22/500\n","500/500 [==============================] - 0s 224us/step - loss: 2.1566 - acc: 0.2180 - val_loss: 2.2001 - val_acc: 0.1660\n","Epoch 23/500\n","500/500 [==============================] - 0s 219us/step - loss: 2.1439 - acc: 0.1800 - val_loss: 2.2002 - val_acc: 0.1660\n","Epoch 24/500\n","500/500 [==============================] - 0s 228us/step - loss: 2.1617 - acc: 0.1900 - val_loss: 2.1611 - val_acc: 0.1720\n","Epoch 25/500\n","500/500 [==============================] - 0s 216us/step - loss: 2.1616 - acc: 0.1840 - val_loss: 2.2007 - val_acc: 0.1600\n","Epoch 26/500\n","128/500 [======>.......................] - ETA: 0s - loss: 2.0680 - acc: 0.2266"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 226us/step - loss: 2.1555 - acc: 0.2140 - val_loss: 2.1465 - val_acc: 0.1920\n","Epoch 27/500\n","500/500 [==============================] - 0s 222us/step - loss: 2.1221 - acc: 0.2020 - val_loss: 2.2585 - val_acc: 0.1480\n","Epoch 28/500\n","500/500 [==============================] - 0s 225us/step - loss: 2.1810 - acc: 0.1700 - val_loss: 2.0991 - val_acc: 0.2180\n","Epoch 29/500\n","500/500 [==============================] - 0s 215us/step - loss: 2.1423 - acc: 0.1980 - val_loss: 2.1784 - val_acc: 0.1760\n","Epoch 30/500\n","500/500 [==============================] - 0s 223us/step - loss: 2.1448 - acc: 0.1740 - val_loss: 2.1719 - val_acc: 0.1720\n","Epoch 31/500\n","500/500 [==============================] - 0s 217us/step - loss: 2.1257 - acc: 0.2200 - val_loss: 2.0907 - val_acc: 0.2140\n","Epoch 32/500\n","500/500 [==============================] - 0s 220us/step - loss: 2.1760 - acc: 0.1820 - val_loss: 2.1408 - val_acc: 0.1920\n","Epoch 33/500\n","500/500 [==============================] - 0s 222us/step - loss: 2.0646 - acc: 0.2500 - val_loss: 2.0698 - val_acc: 0.2120\n","Epoch 34/500\n","500/500 [==============================] - 0s 229us/step - loss: 2.1321 - acc: 0.1940 - val_loss: 2.1013 - val_acc: 0.2000\n","Epoch 35/500\n","500/500 [==============================] - 0s 203us/step - loss: 2.0559 - acc: 0.2400 - val_loss: 2.5419 - val_acc: 0.1440\n","Epoch 36/500\n","500/500 [==============================] - 0s 223us/step - loss: 2.2765 - acc: 0.1960 - val_loss: 2.0376 - val_acc: 0.2740\n","Epoch 37/500\n","500/500 [==============================] - 0s 234us/step - loss: 2.0105 - acc: 0.2540 - val_loss: 2.1095 - val_acc: 0.2040\n","Epoch 38/500\n","500/500 [==============================] - 0s 213us/step - loss: 2.0714 - acc: 0.2120 - val_loss: 2.4072 - val_acc: 0.1500\n","Epoch 39/500\n","500/500 [==============================] - 0s 216us/step - loss: 2.1939 - acc: 0.2240 - val_loss: 2.0158 - val_acc: 0.2620\n","Epoch 40/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.9893 - acc: 0.2520 - val_loss: 2.2679 - val_acc: 0.1660\n","Epoch 41/500\n","500/500 [==============================] - 0s 228us/step - loss: 2.0846 - acc: 0.2020 - val_loss: 2.0910 - val_acc: 0.2020\n","Epoch 42/500\n","500/500 [==============================] - 0s 206us/step - loss: 2.0617 - acc: 0.2280 - val_loss: 1.9649 - val_acc: 0.3020\n","Epoch 43/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.9546 - acc: 0.2540 - val_loss: 2.3798 - val_acc: 0.1560\n","Epoch 44/500\n","500/500 [==============================] - 0s 211us/step - loss: 2.2008 - acc: 0.1960 - val_loss: 1.9638 - val_acc: 0.2660\n","Epoch 45/500\n","500/500 [==============================] - 0s 226us/step - loss: 2.0241 - acc: 0.2640 - val_loss: 2.0891 - val_acc: 0.2460\n","Epoch 46/500\n","500/500 [==============================] - 0s 215us/step - loss: 2.0587 - acc: 0.2280 - val_loss: 1.9402 - val_acc: 0.2840\n","Epoch 47/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.8782 - acc: 0.3160 - val_loss: 1.9155 - val_acc: 0.2720\n","Epoch 48/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.9158 - acc: 0.2780 - val_loss: 2.3431 - val_acc: 0.1640\n","Epoch 49/500\n","500/500 [==============================] - 0s 225us/step - loss: 2.2304 - acc: 0.1880 - val_loss: 1.9257 - val_acc: 0.3040\n","Epoch 50/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.8675 - acc: 0.3200 - val_loss: 1.9202 - val_acc: 0.2900\n","Epoch 51/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.8197 - acc: 0.2920 - val_loss: 1.8696 - val_acc: 0.3200\n","Epoch 52/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.7735 - acc: 0.3281"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 227us/step - loss: 2.0092 - acc: 0.2460 - val_loss: 2.2812 - val_acc: 0.2020\n","Epoch 53/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.9470 - acc: 0.3180 - val_loss: 1.8491 - val_acc: 0.3060\n","Epoch 54/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.9073 - acc: 0.2700 - val_loss: 1.9471 - val_acc: 0.2800\n","Epoch 55/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.9899 - acc: 0.2520 - val_loss: 1.8566 - val_acc: 0.3020\n","Epoch 56/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.7720 - acc: 0.3680 - val_loss: 1.8216 - val_acc: 0.3220\n","Epoch 57/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.8268 - acc: 0.3500 - val_loss: 2.0933 - val_acc: 0.2120\n","Epoch 58/500\n","500/500 [==============================] - 0s 226us/step - loss: 1.9401 - acc: 0.2560 - val_loss: 1.8300 - val_acc: 0.3260\n","Epoch 59/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.9541 - acc: 0.2780 - val_loss: 1.8764 - val_acc: 0.2840\n","Epoch 60/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.8439 - acc: 0.2980 - val_loss: 1.8285 - val_acc: 0.3020\n","Epoch 61/500\n","500/500 [==============================] - 0s 227us/step - loss: 1.8171 - acc: 0.3220 - val_loss: 1.8769 - val_acc: 0.2900\n","Epoch 62/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.8302 - acc: 0.3020 - val_loss: 1.9441 - val_acc: 0.3020\n","Epoch 63/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.8491 - acc: 0.2940 - val_loss: 1.7640 - val_acc: 0.3020\n","Epoch 64/500\n","500/500 [==============================] - 0s 233us/step - loss: 1.7617 - acc: 0.3140 - val_loss: 1.9250 - val_acc: 0.2540\n","Epoch 65/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.8523 - acc: 0.3140 - val_loss: 1.9729 - val_acc: 0.3000\n","Epoch 66/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.8941 - acc: 0.2920 - val_loss: 1.8704 - val_acc: 0.2700\n","Epoch 67/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.8205 - acc: 0.3020 - val_loss: 1.8983 - val_acc: 0.2700\n","Epoch 68/500\n","500/500 [==============================] - 0s 230us/step - loss: 1.8295 - acc: 0.3160 - val_loss: 1.7451 - val_acc: 0.3360\n","Epoch 69/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.7029 - acc: 0.3540 - val_loss: 1.7479 - val_acc: 0.3140\n","Epoch 70/500\n","500/500 [==============================] - 0s 224us/step - loss: 1.6920 - acc: 0.3560 - val_loss: 1.9062 - val_acc: 0.2760\n","Epoch 71/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.6678 - acc: 0.3520 - val_loss: 1.8979 - val_acc: 0.2940\n","Epoch 72/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.9860 - acc: 0.2840 - val_loss: 1.8529 - val_acc: 0.3040\n","Epoch 73/500\n","500/500 [==============================] - 0s 196us/step - loss: 1.7248 - acc: 0.3540 - val_loss: 1.7674 - val_acc: 0.3320\n","Epoch 74/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.7390 - acc: 0.3160 - val_loss: 1.8024 - val_acc: 0.2920\n","Epoch 75/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.6615 - acc: 0.3880 - val_loss: 1.8579 - val_acc: 0.2760\n","Epoch 76/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.8518 - acc: 0.2900 - val_loss: 1.7561 - val_acc: 0.3280\n","Epoch 77/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.6580 - acc: 0.4000 - val_loss: 1.8584 - val_acc: 0.3300\n","Epoch 78/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.7867 - acc: 0.3047"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 202us/step - loss: 1.8047 - acc: 0.3140 - val_loss: 1.8520 - val_acc: 0.2800\n","Epoch 79/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.7936 - acc: 0.3000 - val_loss: 1.7263 - val_acc: 0.3300\n","Epoch 80/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.6683 - acc: 0.3780 - val_loss: 1.7275 - val_acc: 0.3360\n","Epoch 81/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.6376 - acc: 0.3780 - val_loss: 1.7079 - val_acc: 0.3260\n","Epoch 82/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.5933 - acc: 0.4100 - val_loss: 1.7045 - val_acc: 0.3440\n","Epoch 83/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.7030 - acc: 0.3580 - val_loss: 2.1298 - val_acc: 0.2240\n","Epoch 84/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.9142 - acc: 0.2960 - val_loss: 1.7474 - val_acc: 0.3320\n","Epoch 85/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.6377 - acc: 0.4000 - val_loss: 1.7720 - val_acc: 0.3100\n","Epoch 86/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.7282 - acc: 0.3480 - val_loss: 1.7107 - val_acc: 0.3460\n","Epoch 87/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.6165 - acc: 0.3940 - val_loss: 1.7451 - val_acc: 0.3400\n","Epoch 88/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.6886 - acc: 0.3720 - val_loss: 1.6496 - val_acc: 0.3660\n","Epoch 89/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.6014 - acc: 0.3820 - val_loss: 1.6815 - val_acc: 0.3460\n","Epoch 90/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.6450 - acc: 0.3800 - val_loss: 1.6798 - val_acc: 0.3600\n","Epoch 91/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.6063 - acc: 0.3980 - val_loss: 1.8019 - val_acc: 0.3180\n","Epoch 92/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.7554 - acc: 0.3220 - val_loss: 1.7291 - val_acc: 0.3200\n","Epoch 93/500\n","500/500 [==============================] - 0s 230us/step - loss: 1.6459 - acc: 0.4200 - val_loss: 1.6774 - val_acc: 0.3540\n","Epoch 94/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.5840 - acc: 0.4160 - val_loss: 1.7394 - val_acc: 0.3380\n","Epoch 95/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.6791 - acc: 0.3700 - val_loss: 1.6982 - val_acc: 0.3360\n","Epoch 96/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.5548 - acc: 0.4160 - val_loss: 1.6247 - val_acc: 0.3860\n","Epoch 97/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.5432 - acc: 0.4440 - val_loss: 1.7098 - val_acc: 0.3340\n","Epoch 98/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.6335 - acc: 0.3820 - val_loss: 1.7635 - val_acc: 0.3640\n","Epoch 99/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.5761 - acc: 0.4480 - val_loss: 1.6214 - val_acc: 0.3780\n","Epoch 100/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.5515 - acc: 0.4440 - val_loss: 1.6180 - val_acc: 0.3860\n","Epoch 101/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.5020 - acc: 0.4380 - val_loss: 1.6127 - val_acc: 0.3960\n","Epoch 102/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.6129 - acc: 0.3740 - val_loss: 1.9639 - val_acc: 0.2860\n","Epoch 103/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.7507 - acc: 0.3320 - val_loss: 1.7002 - val_acc: 0.3480\n","Epoch 104/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.6343 - acc: 0.4219"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 208us/step - loss: 1.5226 - acc: 0.4320 - val_loss: 1.6214 - val_acc: 0.3820\n","Epoch 105/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.4945 - acc: 0.4200 - val_loss: 1.7417 - val_acc: 0.3360\n","Epoch 106/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.7598 - acc: 0.3360 - val_loss: 1.7105 - val_acc: 0.3480\n","Epoch 107/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.5666 - acc: 0.4160 - val_loss: 1.6330 - val_acc: 0.3840\n","Epoch 108/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.5417 - acc: 0.4240 - val_loss: 1.6477 - val_acc: 0.3640\n","Epoch 109/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.5494 - acc: 0.4060 - val_loss: 1.7013 - val_acc: 0.3440\n","Epoch 110/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.5904 - acc: 0.3780 - val_loss: 1.6791 - val_acc: 0.3400\n","Epoch 111/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.4895 - acc: 0.4560 - val_loss: 1.5963 - val_acc: 0.3920\n","Epoch 112/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.5832 - acc: 0.4240 - val_loss: 1.7407 - val_acc: 0.3500\n","Epoch 113/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.6030 - acc: 0.4060 - val_loss: 1.6774 - val_acc: 0.3540\n","Epoch 114/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.4919 - acc: 0.4680 - val_loss: 1.6729 - val_acc: 0.3780\n","Epoch 115/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.6100 - acc: 0.3960 - val_loss: 1.6101 - val_acc: 0.4040\n","Epoch 116/500\n","500/500 [==============================] - 0s 225us/step - loss: 1.5016 - acc: 0.4520 - val_loss: 1.7364 - val_acc: 0.3200\n","Epoch 117/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.6915 - acc: 0.3300 - val_loss: 1.5815 - val_acc: 0.3940\n","Epoch 118/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.4669 - acc: 0.4740 - val_loss: 1.5871 - val_acc: 0.4040\n","Epoch 119/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.5484 - acc: 0.4100 - val_loss: 1.7464 - val_acc: 0.3200\n","Epoch 120/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.5563 - acc: 0.3920 - val_loss: 1.6237 - val_acc: 0.3620\n","Epoch 121/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.4541 - acc: 0.4580 - val_loss: 1.5941 - val_acc: 0.4060\n","Epoch 122/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.5324 - acc: 0.4560 - val_loss: 1.7410 - val_acc: 0.3300\n","Epoch 123/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.6323 - acc: 0.3740 - val_loss: 1.6749 - val_acc: 0.3480\n","Epoch 124/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.5197 - acc: 0.4240 - val_loss: 1.5765 - val_acc: 0.4040\n","Epoch 125/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.4978 - acc: 0.4420 - val_loss: 1.7615 - val_acc: 0.3200\n","Epoch 126/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.5367 - acc: 0.4100 - val_loss: 1.5870 - val_acc: 0.4320\n","Epoch 127/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.4908 - acc: 0.4460 - val_loss: 1.6863 - val_acc: 0.3700\n","Epoch 128/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.4965 - acc: 0.4420 - val_loss: 1.5761 - val_acc: 0.4320\n","Epoch 129/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.4396 - acc: 0.4840 - val_loss: 1.6438 - val_acc: 0.3960\n","Epoch 130/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.4695 - acc: 0.4375"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 213us/step - loss: 1.4951 - acc: 0.4280 - val_loss: 1.5794 - val_acc: 0.3880\n","Epoch 131/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.4109 - acc: 0.5000 - val_loss: 1.5980 - val_acc: 0.3920\n","Epoch 132/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.6048 - acc: 0.3760 - val_loss: 1.6332 - val_acc: 0.3700\n","Epoch 133/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.4457 - acc: 0.4460 - val_loss: 1.5932 - val_acc: 0.3880\n","Epoch 134/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.4663 - acc: 0.4640 - val_loss: 1.5843 - val_acc: 0.3980\n","Epoch 135/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.4866 - acc: 0.4540 - val_loss: 1.5972 - val_acc: 0.3940\n","Epoch 136/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.4550 - acc: 0.4540 - val_loss: 1.5596 - val_acc: 0.4100\n","Epoch 137/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.4556 - acc: 0.4640 - val_loss: 1.6333 - val_acc: 0.3960\n","Epoch 138/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.4771 - acc: 0.4300 - val_loss: 1.6195 - val_acc: 0.3780\n","Epoch 139/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.5408 - acc: 0.3920 - val_loss: 1.5574 - val_acc: 0.4300\n","Epoch 140/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.4271 - acc: 0.4680 - val_loss: 1.5679 - val_acc: 0.3840\n","Epoch 141/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.4260 - acc: 0.4740 - val_loss: 1.6216 - val_acc: 0.3740\n","Epoch 142/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.5310 - acc: 0.4240 - val_loss: 1.5465 - val_acc: 0.4120\n","Epoch 143/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.4846 - acc: 0.4160 - val_loss: 1.5471 - val_acc: 0.4120\n","Epoch 144/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.3975 - acc: 0.4820 - val_loss: 1.5507 - val_acc: 0.4320\n","Epoch 145/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.4140 - acc: 0.4800 - val_loss: 1.6152 - val_acc: 0.4020\n","Epoch 146/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.4517 - acc: 0.4740 - val_loss: 1.5516 - val_acc: 0.4160\n","Epoch 147/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.4789 - acc: 0.4340 - val_loss: 1.5866 - val_acc: 0.3760\n","Epoch 148/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.4949 - acc: 0.4240 - val_loss: 1.5497 - val_acc: 0.4140\n","Epoch 149/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.4587 - acc: 0.4480 - val_loss: 1.6435 - val_acc: 0.3520\n","Epoch 150/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.4536 - acc: 0.4480 - val_loss: 1.5472 - val_acc: 0.4000\n","Epoch 151/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.4229 - acc: 0.4720 - val_loss: 1.5366 - val_acc: 0.4140\n","Epoch 152/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.4559 - acc: 0.4760 - val_loss: 1.5810 - val_acc: 0.3840\n","Epoch 153/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.4233 - acc: 0.4580 - val_loss: 1.6595 - val_acc: 0.3880\n","Epoch 154/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.4147 - acc: 0.4920 - val_loss: 1.5617 - val_acc: 0.4260\n","Epoch 155/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.4469 - acc: 0.4520 - val_loss: 1.6354 - val_acc: 0.3860\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 156/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.3753 - acc: 0.4880 - val_loss: 1.5670 - val_acc: 0.4120\n","Epoch 157/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.4343 - acc: 0.4660 - val_loss: 1.5041 - val_acc: 0.4500\n","Epoch 158/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.4401 - acc: 0.4760 - val_loss: 1.7007 - val_acc: 0.3660\n","Epoch 159/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.4976 - acc: 0.4180 - val_loss: 1.5121 - val_acc: 0.4400\n","Epoch 160/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3703 - acc: 0.5280 - val_loss: 1.4992 - val_acc: 0.4260\n","Epoch 161/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.4669 - acc: 0.4620 - val_loss: 1.5274 - val_acc: 0.4100\n","Epoch 162/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.3685 - acc: 0.4660 - val_loss: 1.4953 - val_acc: 0.4500\n","Epoch 163/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.3580 - acc: 0.4960 - val_loss: 1.5739 - val_acc: 0.4120\n","Epoch 164/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.4414 - acc: 0.4460 - val_loss: 1.5650 - val_acc: 0.4020\n","Epoch 165/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.3826 - acc: 0.4940 - val_loss: 1.4846 - val_acc: 0.4420\n","Epoch 166/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.3948 - acc: 0.4440 - val_loss: 1.6066 - val_acc: 0.3980\n","Epoch 167/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.4189 - acc: 0.4540 - val_loss: 1.5548 - val_acc: 0.4180\n","Epoch 168/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.4222 - acc: 0.4820 - val_loss: 1.5077 - val_acc: 0.4380\n","Epoch 169/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.3562 - acc: 0.5020 - val_loss: 1.4697 - val_acc: 0.4500\n","Epoch 170/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.3426 - acc: 0.5140 - val_loss: 1.5586 - val_acc: 0.4320\n","Epoch 171/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.3362 - acc: 0.5100 - val_loss: 1.5168 - val_acc: 0.4120\n","Epoch 172/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.3604 - acc: 0.5260 - val_loss: 1.4570 - val_acc: 0.4580\n","Epoch 173/500\n","500/500 [==============================] - 0s 233us/step - loss: 1.3559 - acc: 0.5180 - val_loss: 1.4685 - val_acc: 0.4500\n","Epoch 174/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.3394 - acc: 0.5000 - val_loss: 1.4792 - val_acc: 0.4500\n","Epoch 175/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3537 - acc: 0.5060 - val_loss: 1.6978 - val_acc: 0.3540\n","Epoch 176/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.3575 - acc: 0.4900 - val_loss: 1.4660 - val_acc: 0.4440\n","Epoch 177/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3946 - acc: 0.4620 - val_loss: 1.6872 - val_acc: 0.3480\n","Epoch 178/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.5684 - acc: 0.3920 - val_loss: 1.4758 - val_acc: 0.4440\n","Epoch 179/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.3520 - acc: 0.5200 - val_loss: 1.4702 - val_acc: 0.4440\n","Epoch 180/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.3484 - acc: 0.5020 - val_loss: 1.4803 - val_acc: 0.4520\n","Epoch 181/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.3499 - acc: 0.5180 - val_loss: 1.5632 - val_acc: 0.4160\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 182/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.3749 - acc: 0.4600 - val_loss: 1.4419 - val_acc: 0.4560\n","Epoch 183/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.3337 - acc: 0.5100 - val_loss: 1.4599 - val_acc: 0.4480\n","Epoch 184/500\n","500/500 [==============================] - 0s 221us/step - loss: 1.3221 - acc: 0.5060 - val_loss: 1.4840 - val_acc: 0.4380\n","Epoch 185/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.3350 - acc: 0.4900 - val_loss: 1.4910 - val_acc: 0.4360\n","Epoch 186/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.4102 - acc: 0.4440 - val_loss: 1.4601 - val_acc: 0.4400\n","Epoch 187/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.3242 - acc: 0.5360 - val_loss: 1.4553 - val_acc: 0.4560\n","Epoch 188/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.3101 - acc: 0.5380 - val_loss: 1.4320 - val_acc: 0.4580\n","Epoch 189/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.4220 - acc: 0.4500 - val_loss: 1.5099 - val_acc: 0.4240\n","Epoch 190/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.3820 - acc: 0.5120 - val_loss: 1.4361 - val_acc: 0.4660\n","Epoch 191/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.2638 - acc: 0.5540 - val_loss: 1.4265 - val_acc: 0.4760\n","Epoch 192/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.3197 - acc: 0.5160 - val_loss: 1.4316 - val_acc: 0.4820\n","Epoch 193/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.3164 - acc: 0.5120 - val_loss: 1.4812 - val_acc: 0.4520\n","Epoch 194/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.3526 - acc: 0.4860 - val_loss: 1.4280 - val_acc: 0.4640\n","Epoch 195/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.2618 - acc: 0.5320 - val_loss: 1.4486 - val_acc: 0.4700\n","Epoch 196/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.2686 - acc: 0.5360 - val_loss: 1.4894 - val_acc: 0.4640\n","Epoch 197/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.4797 - acc: 0.4240 - val_loss: 1.4522 - val_acc: 0.4600\n","Epoch 198/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.3030 - acc: 0.5480 - val_loss: 1.4129 - val_acc: 0.4820\n","Epoch 199/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.3057 - acc: 0.5280 - val_loss: 1.4220 - val_acc: 0.4720\n","Epoch 200/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.2999 - acc: 0.5100 - val_loss: 1.4045 - val_acc: 0.4740\n","Epoch 201/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.2427 - acc: 0.5440 - val_loss: 1.4198 - val_acc: 0.4800\n","Epoch 202/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.3846 - acc: 0.4740 - val_loss: 1.4463 - val_acc: 0.4600\n","Epoch 203/500\n","500/500 [==============================] - 0s 227us/step - loss: 1.3392 - acc: 0.5020 - val_loss: 1.4511 - val_acc: 0.4480\n","Epoch 204/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.3347 - acc: 0.5100 - val_loss: 1.3991 - val_acc: 0.4920\n","Epoch 205/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.2688 - acc: 0.5500 - val_loss: 1.4011 - val_acc: 0.4740\n","Epoch 206/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.2738 - acc: 0.5200 - val_loss: 1.4721 - val_acc: 0.4700\n","Epoch 207/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.3074 - acc: 0.5140 - val_loss: 1.4108 - val_acc: 0.4740\n","Epoch 208/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.1769 - acc: 0.5625"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 205us/step - loss: 1.2380 - acc: 0.5180 - val_loss: 1.3769 - val_acc: 0.4900\n","Epoch 209/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.2294 - acc: 0.5700 - val_loss: 1.3911 - val_acc: 0.4800\n","Epoch 210/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.3711 - acc: 0.5080 - val_loss: 1.5011 - val_acc: 0.4380\n","Epoch 211/500\n","500/500 [==============================] - 0s 224us/step - loss: 1.3193 - acc: 0.5500 - val_loss: 1.4105 - val_acc: 0.4880\n","Epoch 212/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2328 - acc: 0.5660 - val_loss: 1.4242 - val_acc: 0.4780\n","Epoch 213/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.3963 - acc: 0.4900 - val_loss: 1.3789 - val_acc: 0.4780\n","Epoch 214/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.2496 - acc: 0.5600 - val_loss: 1.3886 - val_acc: 0.4900\n","Epoch 215/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.3578 - acc: 0.5060 - val_loss: 1.4267 - val_acc: 0.4700\n","Epoch 216/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.2583 - acc: 0.5460 - val_loss: 1.3553 - val_acc: 0.4940\n","Epoch 217/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.2228 - acc: 0.5720 - val_loss: 1.3936 - val_acc: 0.4760\n","Epoch 218/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.2861 - acc: 0.5340 - val_loss: 1.4231 - val_acc: 0.4680\n","Epoch 219/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3506 - acc: 0.4820 - val_loss: 1.5313 - val_acc: 0.4000\n","Epoch 220/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.3045 - acc: 0.5180 - val_loss: 1.3484 - val_acc: 0.5080\n","Epoch 221/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.2258 - acc: 0.5820 - val_loss: 1.3708 - val_acc: 0.5040\n","Epoch 222/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.2956 - acc: 0.4880 - val_loss: 1.3956 - val_acc: 0.4960\n","Epoch 223/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2715 - acc: 0.5420 - val_loss: 1.3380 - val_acc: 0.5180\n","Epoch 224/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.2660 - acc: 0.5440 - val_loss: 1.3636 - val_acc: 0.5000\n","Epoch 225/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.2069 - acc: 0.5580 - val_loss: 1.3662 - val_acc: 0.4940\n","Epoch 226/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2653 - acc: 0.5340 - val_loss: 1.3507 - val_acc: 0.4940\n","Epoch 227/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2466 - acc: 0.5300 - val_loss: 1.3579 - val_acc: 0.5080\n","Epoch 228/500\n","500/500 [==============================] - 0s 230us/step - loss: 1.2479 - acc: 0.5520 - val_loss: 1.3621 - val_acc: 0.4980\n","Epoch 229/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.1975 - acc: 0.5740 - val_loss: 1.3053 - val_acc: 0.5300\n","Epoch 230/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.1916 - acc: 0.5660 - val_loss: 1.4008 - val_acc: 0.4700\n","Epoch 231/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.2644 - acc: 0.5640 - val_loss: 1.3341 - val_acc: 0.4880\n","Epoch 232/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.1997 - acc: 0.5960 - val_loss: 1.3222 - val_acc: 0.5440\n","Epoch 233/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2661 - acc: 0.5360 - val_loss: 1.3205 - val_acc: 0.5400\n","Epoch 234/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.2073 - acc: 0.5547"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 210us/step - loss: 1.2094 - acc: 0.5580 - val_loss: 1.3117 - val_acc: 0.5180\n","Epoch 235/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.2460 - acc: 0.5480 - val_loss: 1.3187 - val_acc: 0.5360\n","Epoch 236/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.1905 - acc: 0.5760 - val_loss: 1.3120 - val_acc: 0.5200\n","Epoch 237/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.2640 - acc: 0.5280 - val_loss: 1.3378 - val_acc: 0.5200\n","Epoch 238/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.2736 - acc: 0.5340 - val_loss: 1.3049 - val_acc: 0.5140\n","Epoch 239/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.1706 - acc: 0.5780 - val_loss: 1.4013 - val_acc: 0.4620\n","Epoch 240/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.3326 - acc: 0.5080 - val_loss: 1.3559 - val_acc: 0.4920\n","Epoch 241/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.2160 - acc: 0.5620 - val_loss: 1.3595 - val_acc: 0.4800\n","Epoch 242/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.1904 - acc: 0.5860 - val_loss: 1.2961 - val_acc: 0.5420\n","Epoch 243/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.1744 - acc: 0.5880 - val_loss: 1.3609 - val_acc: 0.4820\n","Epoch 244/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.1678 - acc: 0.5720 - val_loss: 1.2874 - val_acc: 0.5400\n","Epoch 245/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.2704 - acc: 0.5500 - val_loss: 1.3997 - val_acc: 0.4720\n","Epoch 246/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.2064 - acc: 0.5320 - val_loss: 1.2670 - val_acc: 0.5500\n","Epoch 247/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.1943 - acc: 0.5920 - val_loss: 1.3089 - val_acc: 0.5100\n","Epoch 248/500\n","500/500 [==============================] - 0s 228us/step - loss: 1.1889 - acc: 0.5860 - val_loss: 1.2806 - val_acc: 0.5100\n","Epoch 249/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.1510 - acc: 0.5960 - val_loss: 1.2583 - val_acc: 0.5600\n","Epoch 250/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.1618 - acc: 0.5620 - val_loss: 1.2698 - val_acc: 0.5220\n","Epoch 251/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.1736 - acc: 0.5600 - val_loss: 1.3044 - val_acc: 0.5320\n","Epoch 252/500\n","500/500 [==============================] - 0s 232us/step - loss: 1.1292 - acc: 0.5800 - val_loss: 1.2491 - val_acc: 0.5800\n","Epoch 253/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.1380 - acc: 0.5900 - val_loss: 1.2841 - val_acc: 0.5420\n","Epoch 254/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.3136 - acc: 0.4920 - val_loss: 1.4236 - val_acc: 0.4560\n","Epoch 255/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.2443 - acc: 0.5420 - val_loss: 1.2618 - val_acc: 0.5720\n","Epoch 256/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.1884 - acc: 0.5780 - val_loss: 1.3299 - val_acc: 0.5020\n","Epoch 257/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.2045 - acc: 0.5400 - val_loss: 1.2578 - val_acc: 0.5580\n","Epoch 258/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.1245 - acc: 0.6000 - val_loss: 1.2594 - val_acc: 0.5320\n","Epoch 259/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.0969 - acc: 0.6100 - val_loss: 1.2384 - val_acc: 0.5620\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 260/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.1175 - acc: 0.5980 - val_loss: 1.2788 - val_acc: 0.5200\n","Epoch 261/500\n","500/500 [==============================] - 0s 225us/step - loss: 1.1534 - acc: 0.5780 - val_loss: 1.2346 - val_acc: 0.5600\n","Epoch 262/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.1152 - acc: 0.5960 - val_loss: 1.3406 - val_acc: 0.5020\n","Epoch 263/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.3106 - acc: 0.5260 - val_loss: 1.2820 - val_acc: 0.5400\n","Epoch 264/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.1782 - acc: 0.5680 - val_loss: 1.2558 - val_acc: 0.5400\n","Epoch 265/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.1403 - acc: 0.5840 - val_loss: 1.2525 - val_acc: 0.5200\n","Epoch 266/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.1622 - acc: 0.5820 - val_loss: 1.2350 - val_acc: 0.5640\n","Epoch 267/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.1043 - acc: 0.6160 - val_loss: 1.2400 - val_acc: 0.5600\n","Epoch 268/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.2096 - acc: 0.5440 - val_loss: 1.2252 - val_acc: 0.5820\n","Epoch 269/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.1734 - acc: 0.5500 - val_loss: 1.2473 - val_acc: 0.5480\n","Epoch 270/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0869 - acc: 0.6260 - val_loss: 1.2133 - val_acc: 0.5760\n","Epoch 271/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.0940 - acc: 0.5940 - val_loss: 1.2244 - val_acc: 0.5600\n","Epoch 272/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0950 - acc: 0.6320 - val_loss: 1.2107 - val_acc: 0.5840\n","Epoch 273/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.0985 - acc: 0.6440 - val_loss: 1.2114 - val_acc: 0.5800\n","Epoch 274/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.1211 - acc: 0.5680 - val_loss: 1.2760 - val_acc: 0.5480\n","Epoch 275/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.1981 - acc: 0.5280 - val_loss: 1.2444 - val_acc: 0.5200\n","Epoch 276/500\n","500/500 [==============================] - 0s 197us/step - loss: 1.2059 - acc: 0.5720 - val_loss: 1.4741 - val_acc: 0.3980\n","Epoch 277/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.2172 - acc: 0.5420 - val_loss: 1.2058 - val_acc: 0.5640\n","Epoch 278/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0988 - acc: 0.6140 - val_loss: 1.2061 - val_acc: 0.5680\n","Epoch 279/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.0898 - acc: 0.6400 - val_loss: 1.3138 - val_acc: 0.4840\n","Epoch 280/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.1138 - acc: 0.6260 - val_loss: 1.3016 - val_acc: 0.4700\n","Epoch 281/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.1046 - acc: 0.6100 - val_loss: 1.2031 - val_acc: 0.5560\n","Epoch 282/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.0895 - acc: 0.6120 - val_loss: 1.1921 - val_acc: 0.5780\n","Epoch 283/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.1855 - acc: 0.5420 - val_loss: 1.2958 - val_acc: 0.5280\n","Epoch 284/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.1594 - acc: 0.5800 - val_loss: 1.2679 - val_acc: 0.5140\n","Epoch 285/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.1021 - acc: 0.6180 - val_loss: 1.1789 - val_acc: 0.5760\n","Epoch 286/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.9963 - acc: 0.6406"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 197us/step - loss: 1.0993 - acc: 0.5880 - val_loss: 1.2839 - val_acc: 0.5100\n","Epoch 287/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.1433 - acc: 0.5640 - val_loss: 1.2837 - val_acc: 0.4980\n","Epoch 288/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.0743 - acc: 0.6360 - val_loss: 1.1812 - val_acc: 0.5800\n","Epoch 289/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.0594 - acc: 0.6320 - val_loss: 1.2408 - val_acc: 0.5280\n","Epoch 290/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.1058 - acc: 0.5840 - val_loss: 1.2205 - val_acc: 0.5440\n","Epoch 291/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.1150 - acc: 0.6180 - val_loss: 1.4238 - val_acc: 0.4460\n","Epoch 292/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.1347 - acc: 0.5820 - val_loss: 1.2301 - val_acc: 0.5360\n","Epoch 293/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.0827 - acc: 0.6100 - val_loss: 1.2127 - val_acc: 0.5500\n","Epoch 294/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.0840 - acc: 0.6020 - val_loss: 1.1690 - val_acc: 0.5880\n","Epoch 295/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.0838 - acc: 0.6240 - val_loss: 1.1681 - val_acc: 0.6040\n","Epoch 296/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.0383 - acc: 0.6340 - val_loss: 1.1790 - val_acc: 0.5440\n","Epoch 297/500\n","500/500 [==============================] - 0s 226us/step - loss: 1.0363 - acc: 0.6160 - val_loss: 1.2063 - val_acc: 0.5400\n","Epoch 298/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.0215 - acc: 0.6380 - val_loss: 1.2271 - val_acc: 0.5180\n","Epoch 299/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.0384 - acc: 0.6240 - val_loss: 1.1829 - val_acc: 0.5560\n","Epoch 300/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.0484 - acc: 0.6420 - val_loss: 1.2011 - val_acc: 0.5360\n","Epoch 301/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.0816 - acc: 0.6260 - val_loss: 1.1562 - val_acc: 0.5620\n","Epoch 302/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0766 - acc: 0.6360 - val_loss: 1.2169 - val_acc: 0.5460\n","Epoch 303/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.0948 - acc: 0.5940 - val_loss: 1.2424 - val_acc: 0.5240\n","Epoch 304/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.1128 - acc: 0.6080 - val_loss: 1.2674 - val_acc: 0.5220\n","Epoch 305/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.1328 - acc: 0.5880 - val_loss: 1.2203 - val_acc: 0.5420\n","Epoch 306/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.0923 - acc: 0.6300 - val_loss: 1.1668 - val_acc: 0.5820\n","Epoch 307/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.0363 - acc: 0.6460 - val_loss: 1.1362 - val_acc: 0.5800\n","Epoch 308/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.1028 - acc: 0.6120 - val_loss: 1.1664 - val_acc: 0.5580\n","Epoch 309/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.9911 - acc: 0.6740 - val_loss: 1.1435 - val_acc: 0.5760\n","Epoch 310/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.0340 - acc: 0.6260 - val_loss: 1.3288 - val_acc: 0.4660\n","Epoch 311/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.0807 - acc: 0.6280 - val_loss: 1.1326 - val_acc: 0.6140\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 312/500\n","500/500 [==============================] - 0s 197us/step - loss: 1.1231 - acc: 0.5860 - val_loss: 1.1754 - val_acc: 0.5980\n","Epoch 313/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.0357 - acc: 0.6320 - val_loss: 1.1802 - val_acc: 0.5720\n","Epoch 314/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.0784 - acc: 0.6200 - val_loss: 1.1625 - val_acc: 0.5780\n","Epoch 315/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.0023 - acc: 0.6460 - val_loss: 1.2352 - val_acc: 0.5480\n","Epoch 316/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.0146 - acc: 0.6340 - val_loss: 1.1387 - val_acc: 0.6020\n","Epoch 317/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.0080 - acc: 0.6380 - val_loss: 1.1346 - val_acc: 0.5740\n","Epoch 318/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0015 - acc: 0.6340 - val_loss: 1.1323 - val_acc: 0.5640\n","Epoch 319/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.0127 - acc: 0.6340 - val_loss: 1.2326 - val_acc: 0.5200\n","Epoch 320/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0585 - acc: 0.6240 - val_loss: 1.1327 - val_acc: 0.5880\n","Epoch 321/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.0178 - acc: 0.6340 - val_loss: 1.1688 - val_acc: 0.5600\n","Epoch 322/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.0710 - acc: 0.6080 - val_loss: 1.1555 - val_acc: 0.5660\n","Epoch 323/500\n","500/500 [==============================] - 0s 219us/step - loss: 0.9879 - acc: 0.6540 - val_loss: 1.1695 - val_acc: 0.5720\n","Epoch 324/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.1119 - acc: 0.6000 - val_loss: 1.1433 - val_acc: 0.5900\n","Epoch 325/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.0115 - acc: 0.6360 - val_loss: 1.1156 - val_acc: 0.6100\n","Epoch 326/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.9908 - acc: 0.6560 - val_loss: 1.1036 - val_acc: 0.6200\n","Epoch 327/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0319 - acc: 0.6300 - val_loss: 1.2011 - val_acc: 0.5700\n","Epoch 328/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.0878 - acc: 0.6060 - val_loss: 1.1619 - val_acc: 0.5740\n","Epoch 329/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.0182 - acc: 0.6440 - val_loss: 1.1353 - val_acc: 0.5760\n","Epoch 330/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.0056 - acc: 0.6280 - val_loss: 1.0976 - val_acc: 0.6200\n","Epoch 331/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.9572 - acc: 0.6420 - val_loss: 1.1976 - val_acc: 0.5440\n","Epoch 332/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.0830 - acc: 0.6140 - val_loss: 1.2454 - val_acc: 0.5140\n","Epoch 333/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0404 - acc: 0.6260 - val_loss: 1.2125 - val_acc: 0.5120\n","Epoch 334/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.9911 - acc: 0.6460 - val_loss: 1.0932 - val_acc: 0.6120\n","Epoch 335/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.0046 - acc: 0.6480 - val_loss: 1.0960 - val_acc: 0.5960\n","Epoch 336/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.9689 - acc: 0.6760 - val_loss: 1.0914 - val_acc: 0.6280\n","Epoch 337/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.0011 - acc: 0.6340 - val_loss: 1.1094 - val_acc: 0.5920\n","Epoch 338/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.9851 - acc: 0.6484"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 211us/step - loss: 0.9963 - acc: 0.6520 - val_loss: 1.1107 - val_acc: 0.6220\n","Epoch 339/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.0410 - acc: 0.6240 - val_loss: 1.2187 - val_acc: 0.5320\n","Epoch 340/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.9988 - acc: 0.6380 - val_loss: 1.1418 - val_acc: 0.5660\n","Epoch 341/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.0631 - acc: 0.6040 - val_loss: 1.2315 - val_acc: 0.5160\n","Epoch 342/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.0352 - acc: 0.6200 - val_loss: 1.1398 - val_acc: 0.5700\n","Epoch 343/500\n","500/500 [==============================] - 0s 199us/step - loss: 0.9546 - acc: 0.6680 - val_loss: 1.1018 - val_acc: 0.6040\n","Epoch 344/500\n","500/500 [==============================] - 0s 218us/step - loss: 0.9591 - acc: 0.6800 - val_loss: 1.1404 - val_acc: 0.5480\n","Epoch 345/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9852 - acc: 0.6720 - val_loss: 1.0877 - val_acc: 0.6120\n","Epoch 346/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.9583 - acc: 0.6720 - val_loss: 1.1264 - val_acc: 0.5680\n","Epoch 347/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.9613 - acc: 0.6900 - val_loss: 1.0789 - val_acc: 0.6240\n","Epoch 348/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.9863 - acc: 0.6600 - val_loss: 1.2215 - val_acc: 0.5200\n","Epoch 349/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.0052 - acc: 0.6240 - val_loss: 1.1402 - val_acc: 0.5500\n","Epoch 350/500\n","500/500 [==============================] - 0s 223us/step - loss: 0.9884 - acc: 0.6640 - val_loss: 1.1311 - val_acc: 0.5600\n","Epoch 351/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0722 - acc: 0.6120 - val_loss: 1.2161 - val_acc: 0.5220\n","Epoch 352/500\n","500/500 [==============================] - 0s 226us/step - loss: 0.9944 - acc: 0.6520 - val_loss: 1.1194 - val_acc: 0.5780\n","Epoch 353/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9737 - acc: 0.6860 - val_loss: 1.1784 - val_acc: 0.5500\n","Epoch 354/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9816 - acc: 0.6560 - val_loss: 1.0911 - val_acc: 0.5840\n","Epoch 355/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.9352 - acc: 0.6760 - val_loss: 1.1028 - val_acc: 0.5780\n","Epoch 356/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.0063 - acc: 0.6300 - val_loss: 1.1828 - val_acc: 0.5340\n","Epoch 357/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.9788 - acc: 0.6660 - val_loss: 1.2188 - val_acc: 0.5140\n","Epoch 358/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.9604 - acc: 0.6740 - val_loss: 1.0797 - val_acc: 0.6200\n","Epoch 359/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.8990 - acc: 0.7280 - val_loss: 1.1140 - val_acc: 0.5880\n","Epoch 360/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.9518 - acc: 0.6740 - val_loss: 1.0771 - val_acc: 0.6180\n","Epoch 361/500\n","500/500 [==============================] - 0s 221us/step - loss: 1.0530 - acc: 0.5980 - val_loss: 1.1834 - val_acc: 0.5860\n","Epoch 362/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.0011 - acc: 0.6340 - val_loss: 1.0960 - val_acc: 0.6020\n","Epoch 363/500\n","500/500 [==============================] - 0s 222us/step - loss: 0.9569 - acc: 0.6720 - val_loss: 1.1551 - val_acc: 0.5540\n","Epoch 364/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.9481 - acc: 0.7031"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 216us/step - loss: 0.9006 - acc: 0.7040 - val_loss: 1.0714 - val_acc: 0.6080\n","Epoch 365/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.8656 - acc: 0.7060 - val_loss: 1.0826 - val_acc: 0.5820\n","Epoch 366/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.9476 - acc: 0.6600 - val_loss: 1.0643 - val_acc: 0.6200\n","Epoch 367/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.9357 - acc: 0.6700 - val_loss: 1.0755 - val_acc: 0.6000\n","Epoch 368/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.9461 - acc: 0.6800 - val_loss: 1.1308 - val_acc: 0.5520\n","Epoch 369/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.9620 - acc: 0.6700 - val_loss: 1.1860 - val_acc: 0.5080\n","Epoch 370/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.9615 - acc: 0.6560 - val_loss: 1.1536 - val_acc: 0.5520\n","Epoch 371/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.9897 - acc: 0.6280 - val_loss: 1.1647 - val_acc: 0.5420\n","Epoch 372/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.0332 - acc: 0.6280 - val_loss: 1.0785 - val_acc: 0.6100\n","Epoch 373/500\n","500/500 [==============================] - 0s 218us/step - loss: 0.9491 - acc: 0.6780 - val_loss: 1.1428 - val_acc: 0.5540\n","Epoch 374/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.9557 - acc: 0.6660 - val_loss: 1.0474 - val_acc: 0.6160\n","Epoch 375/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9302 - acc: 0.6820 - val_loss: 1.0754 - val_acc: 0.5800\n","Epoch 376/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.8846 - acc: 0.7080 - val_loss: 1.0599 - val_acc: 0.5960\n","Epoch 377/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.9148 - acc: 0.7040 - val_loss: 1.1030 - val_acc: 0.5800\n","Epoch 378/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.9064 - acc: 0.6940 - val_loss: 1.2593 - val_acc: 0.5080\n","Epoch 379/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.9886 - acc: 0.6440 - val_loss: 1.1172 - val_acc: 0.5540\n","Epoch 380/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.9166 - acc: 0.6780 - val_loss: 1.1482 - val_acc: 0.5380\n","Epoch 381/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.9006 - acc: 0.7020 - val_loss: 1.1022 - val_acc: 0.6100\n","Epoch 382/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.9299 - acc: 0.6560 - val_loss: 1.0460 - val_acc: 0.6100\n","Epoch 383/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.9015 - acc: 0.6860 - val_loss: 1.0831 - val_acc: 0.5820\n","Epoch 384/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.8911 - acc: 0.6780 - val_loss: 1.1170 - val_acc: 0.5880\n","Epoch 385/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.9769 - acc: 0.6660 - val_loss: 1.0486 - val_acc: 0.6200\n","Epoch 386/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.8939 - acc: 0.6940 - val_loss: 1.0509 - val_acc: 0.6160\n","Epoch 387/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9133 - acc: 0.6840 - val_loss: 1.0567 - val_acc: 0.6140\n","Epoch 388/500\n","500/500 [==============================] - 0s 224us/step - loss: 0.8996 - acc: 0.7120 - val_loss: 1.0392 - val_acc: 0.6260\n","Epoch 389/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.9242 - acc: 0.6940 - val_loss: 1.1042 - val_acc: 0.5940\n","Epoch 390/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.9285 - acc: 0.6719"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 213us/step - loss: 0.9307 - acc: 0.6820 - val_loss: 1.0975 - val_acc: 0.5760\n","Epoch 391/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0150 - acc: 0.6260 - val_loss: 1.2078 - val_acc: 0.5180\n","Epoch 392/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.9510 - acc: 0.6600 - val_loss: 1.0764 - val_acc: 0.5780\n","Epoch 393/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9243 - acc: 0.6940 - val_loss: 1.0526 - val_acc: 0.6300\n","Epoch 394/500\n","500/500 [==============================] - 0s 223us/step - loss: 0.9256 - acc: 0.6900 - val_loss: 1.0402 - val_acc: 0.6220\n","Epoch 395/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.8957 - acc: 0.6900 - val_loss: 1.0845 - val_acc: 0.5760\n","Epoch 396/500\n","500/500 [==============================] - 0s 228us/step - loss: 0.8920 - acc: 0.7040 - val_loss: 1.0647 - val_acc: 0.5880\n","Epoch 397/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.9442 - acc: 0.6820 - val_loss: 1.0864 - val_acc: 0.5820\n","Epoch 398/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.8767 - acc: 0.6920 - val_loss: 1.0160 - val_acc: 0.6440\n","Epoch 399/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.8626 - acc: 0.6980 - val_loss: 1.0858 - val_acc: 0.5980\n","Epoch 400/500\n","500/500 [==============================] - 0s 191us/step - loss: 0.8848 - acc: 0.6660 - val_loss: 1.0248 - val_acc: 0.6300\n","Epoch 401/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9796 - acc: 0.6740 - val_loss: 1.1493 - val_acc: 0.5420\n","Epoch 402/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.8946 - acc: 0.6980 - val_loss: 1.0232 - val_acc: 0.6200\n","Epoch 403/500\n","500/500 [==============================] - 0s 222us/step - loss: 0.8184 - acc: 0.7240 - val_loss: 1.0195 - val_acc: 0.6260\n","Epoch 404/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.8630 - acc: 0.7200 - val_loss: 1.0503 - val_acc: 0.6040\n","Epoch 405/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.8859 - acc: 0.7020 - val_loss: 1.0773 - val_acc: 0.5780\n","Epoch 406/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9172 - acc: 0.6640 - val_loss: 1.0960 - val_acc: 0.5720\n","Epoch 407/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.9152 - acc: 0.6680 - val_loss: 1.1365 - val_acc: 0.5460\n","Epoch 408/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9718 - acc: 0.6560 - val_loss: 1.1255 - val_acc: 0.5640\n","Epoch 409/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.8853 - acc: 0.6960 - val_loss: 1.0648 - val_acc: 0.5880\n","Epoch 410/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.8754 - acc: 0.7020 - val_loss: 1.0256 - val_acc: 0.6500\n","Epoch 411/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.8593 - acc: 0.7180 - val_loss: 1.0177 - val_acc: 0.6380\n","Epoch 412/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.8665 - acc: 0.6920 - val_loss: 1.0253 - val_acc: 0.6400\n","Epoch 413/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8821 - acc: 0.6900 - val_loss: 1.1023 - val_acc: 0.5740\n","Epoch 414/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.8693 - acc: 0.6940 - val_loss: 1.0733 - val_acc: 0.5900\n","Epoch 415/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.8284 - acc: 0.7060 - val_loss: 0.9946 - val_acc: 0.6480\n","Epoch 416/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.7969 - acc: 0.6797"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 207us/step - loss: 0.8421 - acc: 0.6980 - val_loss: 1.0347 - val_acc: 0.6400\n","Epoch 417/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.9313 - acc: 0.6620 - val_loss: 1.0337 - val_acc: 0.6440\n","Epoch 418/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8880 - acc: 0.6800 - val_loss: 1.0000 - val_acc: 0.6320\n","Epoch 419/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.8409 - acc: 0.7220 - val_loss: 1.0812 - val_acc: 0.5700\n","Epoch 420/500\n","500/500 [==============================] - 0s 196us/step - loss: 0.9424 - acc: 0.6900 - val_loss: 1.1182 - val_acc: 0.5560\n","Epoch 421/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.8412 - acc: 0.7200 - val_loss: 0.9969 - val_acc: 0.6600\n","Epoch 422/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.8441 - acc: 0.7040 - val_loss: 1.0358 - val_acc: 0.6340\n","Epoch 423/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.8314 - acc: 0.7240 - val_loss: 0.9920 - val_acc: 0.6460\n","Epoch 424/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.8176 - acc: 0.7200 - val_loss: 1.0346 - val_acc: 0.6240\n","Epoch 425/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.8989 - acc: 0.6780 - val_loss: 1.0471 - val_acc: 0.6340\n","Epoch 426/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9634 - acc: 0.6460 - val_loss: 0.9906 - val_acc: 0.6520\n","Epoch 427/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.8304 - acc: 0.7180 - val_loss: 1.0424 - val_acc: 0.6380\n","Epoch 428/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.8423 - acc: 0.7240 - val_loss: 1.0557 - val_acc: 0.6040\n","Epoch 429/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.9142 - acc: 0.6640 - val_loss: 1.0225 - val_acc: 0.6140\n","Epoch 430/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.8586 - acc: 0.6900 - val_loss: 1.0003 - val_acc: 0.6260\n","Epoch 431/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.8497 - acc: 0.7240 - val_loss: 1.0035 - val_acc: 0.6500\n","Epoch 432/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.7965 - acc: 0.7300 - val_loss: 0.9666 - val_acc: 0.6600\n","Epoch 433/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.8269 - acc: 0.7240 - val_loss: 0.9880 - val_acc: 0.6400\n","Epoch 434/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9106 - acc: 0.6880 - val_loss: 1.0265 - val_acc: 0.6240\n","Epoch 435/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.8295 - acc: 0.7080 - val_loss: 0.9939 - val_acc: 0.6200\n","Epoch 436/500\n","500/500 [==============================] - 0s 218us/step - loss: 0.8234 - acc: 0.7220 - val_loss: 1.0127 - val_acc: 0.6200\n","Epoch 437/500\n","500/500 [==============================] - 0s 195us/step - loss: 0.8069 - acc: 0.7380 - val_loss: 0.9916 - val_acc: 0.6640\n","Epoch 438/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.8223 - acc: 0.7260 - val_loss: 0.9655 - val_acc: 0.6640\n","Epoch 439/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.8375 - acc: 0.6980 - val_loss: 1.0254 - val_acc: 0.6300\n","Epoch 440/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8241 - acc: 0.7300 - val_loss: 0.9775 - val_acc: 0.6500\n","Epoch 441/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.8192 - acc: 0.7200 - val_loss: 1.0256 - val_acc: 0.6100\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 442/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8667 - acc: 0.6880 - val_loss: 1.0775 - val_acc: 0.5720\n","Epoch 443/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.8411 - acc: 0.7440 - val_loss: 1.0076 - val_acc: 0.6140\n","Epoch 444/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.8056 - acc: 0.7280 - val_loss: 1.0625 - val_acc: 0.6240\n","Epoch 445/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9014 - acc: 0.6920 - val_loss: 0.9697 - val_acc: 0.6560\n","Epoch 446/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.8753 - acc: 0.7060 - val_loss: 0.9627 - val_acc: 0.6740\n","Epoch 447/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.8305 - acc: 0.6960 - val_loss: 0.9936 - val_acc: 0.6280\n","Epoch 448/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7490 - acc: 0.7720 - val_loss: 0.9829 - val_acc: 0.6420\n","Epoch 449/500\n","500/500 [==============================] - 0s 220us/step - loss: 0.8254 - acc: 0.7140 - val_loss: 1.2000 - val_acc: 0.5380\n","Epoch 450/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8705 - acc: 0.7020 - val_loss: 0.9617 - val_acc: 0.6520\n","Epoch 451/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.7893 - acc: 0.7460 - val_loss: 0.9406 - val_acc: 0.6720\n","Epoch 452/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8170 - acc: 0.7280 - val_loss: 1.0389 - val_acc: 0.6320\n","Epoch 453/500\n","500/500 [==============================] - 0s 219us/step - loss: 0.8246 - acc: 0.7040 - val_loss: 0.9652 - val_acc: 0.6680\n","Epoch 454/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.7919 - acc: 0.7240 - val_loss: 0.9682 - val_acc: 0.6620\n","Epoch 455/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.7460 - acc: 0.7600 - val_loss: 0.9831 - val_acc: 0.6540\n","Epoch 456/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8484 - acc: 0.7200 - val_loss: 0.9558 - val_acc: 0.6420\n","Epoch 457/500\n","500/500 [==============================] - 0s 222us/step - loss: 0.8292 - acc: 0.7240 - val_loss: 0.9528 - val_acc: 0.6620\n","Epoch 458/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8433 - acc: 0.7160 - val_loss: 0.9431 - val_acc: 0.6860\n","Epoch 459/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.7726 - acc: 0.7380 - val_loss: 0.9635 - val_acc: 0.6360\n","Epoch 460/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.8219 - acc: 0.7140 - val_loss: 1.1268 - val_acc: 0.6120\n","Epoch 461/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.9745 - acc: 0.6760 - val_loss: 0.9832 - val_acc: 0.6360\n","Epoch 462/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.7774 - acc: 0.7340 - val_loss: 0.9794 - val_acc: 0.6220\n","Epoch 463/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.8093 - acc: 0.7240 - val_loss: 0.9701 - val_acc: 0.6640\n","Epoch 464/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.8339 - acc: 0.7060 - val_loss: 0.9544 - val_acc: 0.6600\n","Epoch 465/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.7938 - acc: 0.7300 - val_loss: 0.9522 - val_acc: 0.6480\n","Epoch 466/500\n","500/500 [==============================] - 0s 219us/step - loss: 0.7400 - acc: 0.7620 - val_loss: 1.0207 - val_acc: 0.6040\n","Epoch 467/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.7986 - acc: 0.7240 - val_loss: 0.9342 - val_acc: 0.6740\n","Epoch 468/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.9422 - acc: 0.7031"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 219us/step - loss: 0.8519 - acc: 0.7060 - val_loss: 0.9944 - val_acc: 0.6200\n","Epoch 469/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.7909 - acc: 0.7180 - val_loss: 1.0066 - val_acc: 0.6100\n","Epoch 470/500\n","500/500 [==============================] - 0s 220us/step - loss: 0.7797 - acc: 0.7420 - val_loss: 0.9334 - val_acc: 0.6660\n","Epoch 471/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7876 - acc: 0.7420 - val_loss: 0.9224 - val_acc: 0.6640\n","Epoch 472/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.7760 - acc: 0.7440 - val_loss: 1.0297 - val_acc: 0.6040\n","Epoch 473/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8291 - acc: 0.7080 - val_loss: 0.9825 - val_acc: 0.6460\n","Epoch 474/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.8953 - acc: 0.6600 - val_loss: 1.0678 - val_acc: 0.6200\n","Epoch 475/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.7707 - acc: 0.7420 - val_loss: 0.9493 - val_acc: 0.6400\n","Epoch 476/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.7735 - acc: 0.7480 - val_loss: 0.9769 - val_acc: 0.6440\n","Epoch 477/500\n","500/500 [==============================] - 0s 218us/step - loss: 0.7584 - acc: 0.7320 - val_loss: 0.9410 - val_acc: 0.6800\n","Epoch 478/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.7616 - acc: 0.7300 - val_loss: 1.0028 - val_acc: 0.6440\n","Epoch 479/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.8007 - acc: 0.7080 - val_loss: 0.9637 - val_acc: 0.6560\n","Epoch 480/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.7714 - acc: 0.7200 - val_loss: 0.9605 - val_acc: 0.6280\n","Epoch 481/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7565 - acc: 0.7480 - val_loss: 0.9202 - val_acc: 0.6840\n","Epoch 482/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8052 - acc: 0.7180 - val_loss: 0.9532 - val_acc: 0.6400\n","Epoch 483/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.7874 - acc: 0.7140 - val_loss: 1.0346 - val_acc: 0.5940\n","Epoch 484/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.8457 - acc: 0.6840 - val_loss: 0.9403 - val_acc: 0.6600\n","Epoch 485/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.7315 - acc: 0.7440 - val_loss: 0.9371 - val_acc: 0.6620\n","Epoch 486/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.7371 - acc: 0.7340 - val_loss: 0.9574 - val_acc: 0.6320\n","Epoch 487/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.7579 - acc: 0.7500 - val_loss: 0.9046 - val_acc: 0.6880\n","Epoch 488/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7718 - acc: 0.7280 - val_loss: 0.9525 - val_acc: 0.6500\n","Epoch 489/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.7804 - acc: 0.7180 - val_loss: 0.9468 - val_acc: 0.6960\n","Epoch 490/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.7296 - acc: 0.7440 - val_loss: 0.9540 - val_acc: 0.6560\n","Epoch 491/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.7130 - acc: 0.7540 - val_loss: 1.0045 - val_acc: 0.6160\n","Epoch 492/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.7328 - acc: 0.7440 - val_loss: 0.9554 - val_acc: 0.6320\n","Epoch 493/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.7467 - acc: 0.7480 - val_loss: 0.9287 - val_acc: 0.6700\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 494/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.7329 - acc: 0.7400 - val_loss: 0.9387 - val_acc: 0.6600\n","Epoch 495/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.7747 - acc: 0.7400 - val_loss: 0.9131 - val_acc: 0.6840\n","Epoch 496/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.7997 - acc: 0.7200 - val_loss: 0.9371 - val_acc: 0.6600\n","Epoch 497/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.7280 - acc: 0.7480 - val_loss: 0.9135 - val_acc: 0.7000\n","Epoch 498/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.7837 - acc: 0.7240 - val_loss: 0.9626 - val_acc: 0.6760\n","Epoch 499/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.7820 - acc: 0.7300 - val_loss: 0.9073 - val_acc: 0.6840\n","Epoch 500/500\n","500/500 [==============================] - 0s 195us/step - loss: 0.6918 - acc: 0.7640 - val_loss: 0.9047 - val_acc: 0.6780\n","Test loss: 0.9047084989547729\n","Test accuracy: 0.6779999995231628\n"],"name":"stdout"}]},{"metadata":{"id":"zPcoud3EizbR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":16938},"outputId":"70d5ff1b-1afd-4f91-8db2-c6ea43924e03","executionInfo":{"status":"ok","timestamp":1524891015819,"user_tz":-540,"elapsed":56574,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["init_data(30,20)\n","run_model(epochs = 500)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["x_train shape: (500, 30, 20, 1)\n","500 train samples\n","500 test samples\n","Train on 500 samples, validate on 500 samples\n","Epoch 1/500\n","500/500 [==============================] - 1s 2ms/step - loss: 2.2990 - acc: 0.1040 - val_loss: 2.2999 - val_acc: 0.0840\n","Epoch 2/500\n","500/500 [==============================] - 0s 239us/step - loss: 2.2948 - acc: 0.0860 - val_loss: 2.2977 - val_acc: 0.0860\n","Epoch 3/500\n","500/500 [==============================] - 0s 224us/step - loss: 2.2879 - acc: 0.1140 - val_loss: 2.2965 - val_acc: 0.0880\n","Epoch 4/500\n","500/500 [==============================] - 0s 203us/step - loss: 2.2867 - acc: 0.1080 - val_loss: 2.2944 - val_acc: 0.0940\n","Epoch 5/500\n","500/500 [==============================] - 0s 222us/step - loss: 2.2834 - acc: 0.1140 - val_loss: 2.2917 - val_acc: 0.1360\n","Epoch 6/500\n","500/500 [==============================] - 0s 224us/step - loss: 2.2774 - acc: 0.1280 - val_loss: 2.2886 - val_acc: 0.1740\n","Epoch 7/500\n","500/500 [==============================] - 0s 215us/step - loss: 2.2782 - acc: 0.1200 - val_loss: 2.2863 - val_acc: 0.1520\n","Epoch 8/500\n","500/500 [==============================] - 0s 211us/step - loss: 2.2704 - acc: 0.1200 - val_loss: 2.2829 - val_acc: 0.1760\n","Epoch 9/500\n","500/500 [==============================] - 0s 218us/step - loss: 2.2688 - acc: 0.1340 - val_loss: 2.2786 - val_acc: 0.2020\n","Epoch 10/500\n","500/500 [==============================] - 0s 221us/step - loss: 2.2644 - acc: 0.1760 - val_loss: 2.2753 - val_acc: 0.1960\n","Epoch 11/500\n","500/500 [==============================] - 0s 223us/step - loss: 2.2598 - acc: 0.1660 - val_loss: 2.2689 - val_acc: 0.2200\n","Epoch 12/500\n","500/500 [==============================] - 0s 220us/step - loss: 2.2501 - acc: 0.1660 - val_loss: 2.2635 - val_acc: 0.2200\n","Epoch 13/500\n","500/500 [==============================] - 0s 225us/step - loss: 2.2352 - acc: 0.1920 - val_loss: 2.2641 - val_acc: 0.1880\n","Epoch 14/500\n","500/500 [==============================] - 0s 212us/step - loss: 2.2459 - acc: 0.1660 - val_loss: 2.2513 - val_acc: 0.2060\n","Epoch 15/500\n","500/500 [==============================] - 0s 214us/step - loss: 2.2211 - acc: 0.2040 - val_loss: 2.2363 - val_acc: 0.2120\n","Epoch 16/500\n","500/500 [==============================] - 0s 215us/step - loss: 2.1954 - acc: 0.1960 - val_loss: 2.2291 - val_acc: 0.2060\n","Epoch 17/500\n","500/500 [==============================] - 0s 218us/step - loss: 2.1787 - acc: 0.2220 - val_loss: 2.2069 - val_acc: 0.2100\n","Epoch 18/500\n","500/500 [==============================] - 0s 210us/step - loss: 2.1653 - acc: 0.2260 - val_loss: 2.2250 - val_acc: 0.1580\n","Epoch 19/500\n","500/500 [==============================] - 0s 224us/step - loss: 2.2163 - acc: 0.1680 - val_loss: 2.1778 - val_acc: 0.1980\n","Epoch 20/500\n","500/500 [==============================] - 0s 216us/step - loss: 2.1484 - acc: 0.2100 - val_loss: 2.1598 - val_acc: 0.2000\n","Epoch 21/500\n","500/500 [==============================] - 0s 238us/step - loss: 2.2118 - acc: 0.1920 - val_loss: 2.2304 - val_acc: 0.1480\n","Epoch 22/500\n","500/500 [==============================] - 0s 217us/step - loss: 2.1338 - acc: 0.2100 - val_loss: 2.1195 - val_acc: 0.2500\n","Epoch 23/500\n","500/500 [==============================] - 0s 223us/step - loss: 2.0951 - acc: 0.2420 - val_loss: 2.2371 - val_acc: 0.1480\n","Epoch 24/500\n","500/500 [==============================] - 0s 209us/step - loss: 2.0979 - acc: 0.2380 - val_loss: 2.0916 - val_acc: 0.2260\n","Epoch 25/500\n","500/500 [==============================] - 0s 236us/step - loss: 2.0240 - acc: 0.2540 - val_loss: 2.0950 - val_acc: 0.2300\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 26/500\n","500/500 [==============================] - 0s 217us/step - loss: 2.3308 - acc: 0.1660 - val_loss: 2.1109 - val_acc: 0.2340\n","Epoch 27/500\n","500/500 [==============================] - 0s 245us/step - loss: 2.0596 - acc: 0.2340 - val_loss: 2.1125 - val_acc: 0.2020\n","Epoch 28/500\n","500/500 [==============================] - 0s 240us/step - loss: 2.1460 - acc: 0.1680 - val_loss: 2.2966 - val_acc: 0.1460\n","Epoch 29/500\n","500/500 [==============================] - 0s 230us/step - loss: 2.1390 - acc: 0.1960 - val_loss: 2.0763 - val_acc: 0.2360\n","Epoch 30/500\n","500/500 [==============================] - 0s 229us/step - loss: 1.9917 - acc: 0.2800 - val_loss: 2.0804 - val_acc: 0.2220\n","Epoch 31/500\n","500/500 [==============================] - 0s 217us/step - loss: 2.1157 - acc: 0.2020 - val_loss: 2.2526 - val_acc: 0.2000\n","Epoch 32/500\n","500/500 [==============================] - 0s 216us/step - loss: 2.1473 - acc: 0.1900 - val_loss: 2.0486 - val_acc: 0.2560\n","Epoch 33/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.9893 - acc: 0.2640 - val_loss: 2.3432 - val_acc: 0.1620\n","Epoch 34/500\n","500/500 [==============================] - 0s 234us/step - loss: 2.1990 - acc: 0.1760 - val_loss: 2.1167 - val_acc: 0.2020\n","Epoch 35/500\n","500/500 [==============================] - 0s 216us/step - loss: 2.0348 - acc: 0.2500 - val_loss: 2.1195 - val_acc: 0.2040\n","Epoch 36/500\n","500/500 [==============================] - 0s 225us/step - loss: 2.0707 - acc: 0.2080 - val_loss: 2.0751 - val_acc: 0.2100\n","Epoch 37/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.9590 - acc: 0.2740 - val_loss: 2.0184 - val_acc: 0.2280\n","Epoch 38/500\n","500/500 [==============================] - 0s 230us/step - loss: 2.1146 - acc: 0.1940 - val_loss: 2.1533 - val_acc: 0.2020\n","Epoch 39/500\n","500/500 [==============================] - 0s 214us/step - loss: 2.0302 - acc: 0.2040 - val_loss: 2.0681 - val_acc: 0.2240\n","Epoch 40/500\n","500/500 [==============================] - 0s 218us/step - loss: 2.0753 - acc: 0.2120 - val_loss: 2.1454 - val_acc: 0.2020\n","Epoch 41/500\n","500/500 [==============================] - 0s 227us/step - loss: 1.9603 - acc: 0.2620 - val_loss: 2.0327 - val_acc: 0.2780\n","Epoch 42/500\n","500/500 [==============================] - 0s 216us/step - loss: 2.0649 - acc: 0.2380 - val_loss: 2.1566 - val_acc: 0.2260\n","Epoch 43/500\n","500/500 [==============================] - 0s 217us/step - loss: 2.0414 - acc: 0.2380 - val_loss: 2.1322 - val_acc: 0.2620\n","Epoch 44/500\n","500/500 [==============================] - 0s 209us/step - loss: 2.0995 - acc: 0.2060 - val_loss: 2.0085 - val_acc: 0.2860\n","Epoch 45/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.9214 - acc: 0.3240 - val_loss: 1.9557 - val_acc: 0.2560\n","Epoch 46/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.8917 - acc: 0.3020 - val_loss: 2.2136 - val_acc: 0.1920\n","Epoch 47/500\n","500/500 [==============================] - 0s 215us/step - loss: 2.1239 - acc: 0.2080 - val_loss: 2.0171 - val_acc: 0.2440\n","Epoch 48/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.9721 - acc: 0.2400 - val_loss: 2.0734 - val_acc: 0.2320\n","Epoch 49/500\n","500/500 [==============================] - 0s 220us/step - loss: 2.0314 - acc: 0.2400 - val_loss: 1.9457 - val_acc: 0.2700\n","Epoch 50/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.8631 - acc: 0.3080 - val_loss: 1.9467 - val_acc: 0.2380\n","Epoch 51/500\n","500/500 [==============================] - 0s 224us/step - loss: 2.1187 - acc: 0.2340 - val_loss: 2.0054 - val_acc: 0.2480\n","Epoch 52/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.8732 - acc: 0.3125"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 209us/step - loss: 1.9178 - acc: 0.3120 - val_loss: 1.9432 - val_acc: 0.2560\n","Epoch 53/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.8674 - acc: 0.3080 - val_loss: 1.9875 - val_acc: 0.2340\n","Epoch 54/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.8215 - acc: 0.3180 - val_loss: 1.8625 - val_acc: 0.2860\n","Epoch 55/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.8724 - acc: 0.2840 - val_loss: 2.1602 - val_acc: 0.2600\n","Epoch 56/500\n","500/500 [==============================] - 0s 210us/step - loss: 2.0474 - acc: 0.2340 - val_loss: 1.8864 - val_acc: 0.2940\n","Epoch 57/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.8722 - acc: 0.3240 - val_loss: 1.8610 - val_acc: 0.3140\n","Epoch 58/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.8049 - acc: 0.3300 - val_loss: 2.0246 - val_acc: 0.2360\n","Epoch 59/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.9808 - acc: 0.2500 - val_loss: 2.0743 - val_acc: 0.2600\n","Epoch 60/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.8769 - acc: 0.3340 - val_loss: 1.8114 - val_acc: 0.3340\n","Epoch 61/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.7921 - acc: 0.3220 - val_loss: 1.8230 - val_acc: 0.3140\n","Epoch 62/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.8272 - acc: 0.3280 - val_loss: 1.8938 - val_acc: 0.3220\n","Epoch 63/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.7896 - acc: 0.3160 - val_loss: 1.8209 - val_acc: 0.3320\n","Epoch 64/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.7832 - acc: 0.3280 - val_loss: 1.9130 - val_acc: 0.2960\n","Epoch 65/500\n","500/500 [==============================] - 0s 233us/step - loss: 1.8676 - acc: 0.2940 - val_loss: 1.9319 - val_acc: 0.2700\n","Epoch 66/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.8255 - acc: 0.3180 - val_loss: 1.7909 - val_acc: 0.2980\n","Epoch 67/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.7124 - acc: 0.3460 - val_loss: 1.8648 - val_acc: 0.2980\n","Epoch 68/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.7121 - acc: 0.3480 - val_loss: 1.7956 - val_acc: 0.3120\n","Epoch 69/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.8786 - acc: 0.2720 - val_loss: 1.9362 - val_acc: 0.2840\n","Epoch 70/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.8154 - acc: 0.3560 - val_loss: 1.8279 - val_acc: 0.3120\n","Epoch 71/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.6907 - acc: 0.3940 - val_loss: 1.7466 - val_acc: 0.3180\n","Epoch 72/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.6283 - acc: 0.3960 - val_loss: 1.8261 - val_acc: 0.2980\n","Epoch 73/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.8229 - acc: 0.3140 - val_loss: 1.8758 - val_acc: 0.3320\n","Epoch 74/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.6732 - acc: 0.3800 - val_loss: 1.8638 - val_acc: 0.3440\n","Epoch 75/500\n","500/500 [==============================] - 0s 228us/step - loss: 1.7209 - acc: 0.3580 - val_loss: 1.7487 - val_acc: 0.3520\n","Epoch 76/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.7116 - acc: 0.3460 - val_loss: 1.7348 - val_acc: 0.3300\n","Epoch 77/500\n","500/500 [==============================] - 0s 224us/step - loss: 1.7935 - acc: 0.3220 - val_loss: 1.9169 - val_acc: 0.2740\n","Epoch 78/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.8300 - acc: 0.2969"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 210us/step - loss: 1.8155 - acc: 0.3220 - val_loss: 1.7768 - val_acc: 0.3100\n","Epoch 79/500\n","500/500 [==============================] - 0s 230us/step - loss: 1.7587 - acc: 0.3380 - val_loss: 1.8330 - val_acc: 0.3020\n","Epoch 80/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.6728 - acc: 0.3940 - val_loss: 1.7149 - val_acc: 0.3620\n","Epoch 81/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.6792 - acc: 0.3880 - val_loss: 1.7241 - val_acc: 0.3240\n","Epoch 82/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.6725 - acc: 0.3660 - val_loss: 1.8654 - val_acc: 0.2880\n","Epoch 83/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.6294 - acc: 0.3540 - val_loss: 1.6983 - val_acc: 0.3520\n","Epoch 84/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.7205 - acc: 0.3480 - val_loss: 1.7590 - val_acc: 0.3400\n","Epoch 85/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.6700 - acc: 0.3960 - val_loss: 1.6580 - val_acc: 0.3560\n","Epoch 86/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.6028 - acc: 0.3980 - val_loss: 1.9273 - val_acc: 0.2820\n","Epoch 87/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.7763 - acc: 0.3260 - val_loss: 1.7652 - val_acc: 0.3200\n","Epoch 88/500\n","500/500 [==============================] - 0s 221us/step - loss: 1.6145 - acc: 0.4000 - val_loss: 1.7296 - val_acc: 0.3660\n","Epoch 89/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.7040 - acc: 0.4060 - val_loss: 1.9520 - val_acc: 0.2660\n","Epoch 90/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.7170 - acc: 0.3700 - val_loss: 1.6721 - val_acc: 0.3740\n","Epoch 91/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.6218 - acc: 0.4080 - val_loss: 1.6696 - val_acc: 0.3600\n","Epoch 92/500\n","500/500 [==============================] - 0s 221us/step - loss: 1.5756 - acc: 0.4260 - val_loss: 1.8439 - val_acc: 0.2860\n","Epoch 93/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.6515 - acc: 0.3420 - val_loss: 1.6561 - val_acc: 0.3760\n","Epoch 94/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.5818 - acc: 0.3980 - val_loss: 1.7147 - val_acc: 0.3440\n","Epoch 95/500\n","500/500 [==============================] - 0s 224us/step - loss: 1.6087 - acc: 0.3740 - val_loss: 1.7037 - val_acc: 0.3640\n","Epoch 96/500\n","500/500 [==============================] - 0s 226us/step - loss: 1.5839 - acc: 0.4180 - val_loss: 1.7271 - val_acc: 0.3500\n","Epoch 97/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.7476 - acc: 0.3300 - val_loss: 1.7814 - val_acc: 0.3120\n","Epoch 98/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.7118 - acc: 0.3940 - val_loss: 1.6526 - val_acc: 0.3580\n","Epoch 99/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.5290 - acc: 0.4420 - val_loss: 1.7363 - val_acc: 0.3380\n","Epoch 100/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.5953 - acc: 0.3900 - val_loss: 1.6543 - val_acc: 0.3640\n","Epoch 101/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.5318 - acc: 0.4160 - val_loss: 1.6392 - val_acc: 0.3880\n","Epoch 102/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.5494 - acc: 0.4360 - val_loss: 1.6570 - val_acc: 0.3780\n","Epoch 103/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.5645 - acc: 0.4080 - val_loss: 1.8358 - val_acc: 0.3080\n","Epoch 104/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.5837 - acc: 0.3984"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 226us/step - loss: 1.6033 - acc: 0.3800 - val_loss: 1.6937 - val_acc: 0.3560\n","Epoch 105/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.5087 - acc: 0.4500 - val_loss: 1.6614 - val_acc: 0.3340\n","Epoch 106/500\n","500/500 [==============================] - 0s 226us/step - loss: 1.6390 - acc: 0.3820 - val_loss: 1.8775 - val_acc: 0.2740\n","Epoch 107/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.7050 - acc: 0.3760 - val_loss: 1.6639 - val_acc: 0.3820\n","Epoch 108/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.5048 - acc: 0.4360 - val_loss: 1.6282 - val_acc: 0.3860\n","Epoch 109/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.5589 - acc: 0.4140 - val_loss: 1.7211 - val_acc: 0.3380\n","Epoch 110/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.5274 - acc: 0.4220 - val_loss: 1.6179 - val_acc: 0.3740\n","Epoch 111/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.5271 - acc: 0.4300 - val_loss: 1.6784 - val_acc: 0.3620\n","Epoch 112/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.6629 - acc: 0.3580 - val_loss: 1.6514 - val_acc: 0.3500\n","Epoch 113/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.5101 - acc: 0.4340 - val_loss: 1.6428 - val_acc: 0.3700\n","Epoch 114/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.4982 - acc: 0.4560 - val_loss: 1.6154 - val_acc: 0.3800\n","Epoch 115/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.5042 - acc: 0.4420 - val_loss: 1.7635 - val_acc: 0.3480\n","Epoch 116/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.5918 - acc: 0.3880 - val_loss: 1.5992 - val_acc: 0.3940\n","Epoch 117/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.4577 - acc: 0.4340 - val_loss: 1.5856 - val_acc: 0.3900\n","Epoch 118/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.4917 - acc: 0.4740 - val_loss: 1.7479 - val_acc: 0.3280\n","Epoch 119/500\n","500/500 [==============================] - 0s 226us/step - loss: 1.5158 - acc: 0.4200 - val_loss: 1.6841 - val_acc: 0.3560\n","Epoch 120/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.5094 - acc: 0.4060 - val_loss: 1.6521 - val_acc: 0.3820\n","Epoch 121/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.5533 - acc: 0.4180 - val_loss: 1.6031 - val_acc: 0.3840\n","Epoch 122/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.4766 - acc: 0.4620 - val_loss: 1.5961 - val_acc: 0.4120\n","Epoch 123/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.5420 - acc: 0.4080 - val_loss: 1.6613 - val_acc: 0.3640\n","Epoch 124/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.4477 - acc: 0.4800 - val_loss: 1.5718 - val_acc: 0.4220\n","Epoch 125/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.4865 - acc: 0.4120 - val_loss: 1.6393 - val_acc: 0.3820\n","Epoch 126/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.5096 - acc: 0.4040 - val_loss: 1.6296 - val_acc: 0.3560\n","Epoch 127/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.6165 - acc: 0.3880 - val_loss: 1.6111 - val_acc: 0.3540\n","Epoch 128/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.4851 - acc: 0.4700 - val_loss: 1.6159 - val_acc: 0.3940\n","Epoch 129/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.4545 - acc: 0.4660 - val_loss: 1.5621 - val_acc: 0.4060\n","Epoch 130/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.4373 - acc: 0.5156"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 209us/step - loss: 1.4331 - acc: 0.4840 - val_loss: 1.6585 - val_acc: 0.3720\n","Epoch 131/500\n","500/500 [==============================] - 0s 228us/step - loss: 1.5981 - acc: 0.3940 - val_loss: 1.6869 - val_acc: 0.3560\n","Epoch 132/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.5104 - acc: 0.4420 - val_loss: 1.5902 - val_acc: 0.3860\n","Epoch 133/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.4451 - acc: 0.4940 - val_loss: 1.5776 - val_acc: 0.3960\n","Epoch 134/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.4233 - acc: 0.4820 - val_loss: 1.7119 - val_acc: 0.3600\n","Epoch 135/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.5075 - acc: 0.4140 - val_loss: 1.6189 - val_acc: 0.3900\n","Epoch 136/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.4424 - acc: 0.4680 - val_loss: 1.5720 - val_acc: 0.4040\n","Epoch 137/500\n","500/500 [==============================] - 0s 221us/step - loss: 1.4809 - acc: 0.4740 - val_loss: 1.5586 - val_acc: 0.4220\n","Epoch 138/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.4633 - acc: 0.4180 - val_loss: 1.5656 - val_acc: 0.4160\n","Epoch 139/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.4542 - acc: 0.4580 - val_loss: 1.5927 - val_acc: 0.3860\n","Epoch 140/500\n","500/500 [==============================] - 0s 239us/step - loss: 1.5969 - acc: 0.4320 - val_loss: 1.5727 - val_acc: 0.4200\n","Epoch 141/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.4163 - acc: 0.4880 - val_loss: 1.5855 - val_acc: 0.3680\n","Epoch 142/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.4304 - acc: 0.4860 - val_loss: 1.5510 - val_acc: 0.4260\n","Epoch 143/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.4219 - acc: 0.4480 - val_loss: 1.5978 - val_acc: 0.3860\n","Epoch 144/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.4381 - acc: 0.4520 - val_loss: 1.5495 - val_acc: 0.4280\n","Epoch 145/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.3698 - acc: 0.5260 - val_loss: 1.5365 - val_acc: 0.4140\n","Epoch 146/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.4162 - acc: 0.4720 - val_loss: 1.5440 - val_acc: 0.4360\n","Epoch 147/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.5155 - acc: 0.4260 - val_loss: 1.5596 - val_acc: 0.4000\n","Epoch 148/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.4212 - acc: 0.4780 - val_loss: 1.5822 - val_acc: 0.3960\n","Epoch 149/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.3644 - acc: 0.5260 - val_loss: 1.5310 - val_acc: 0.4280\n","Epoch 150/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.3828 - acc: 0.5020 - val_loss: 1.5630 - val_acc: 0.4020\n","Epoch 151/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.3869 - acc: 0.5000 - val_loss: 1.5753 - val_acc: 0.4000\n","Epoch 152/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.4630 - acc: 0.4520 - val_loss: 1.5828 - val_acc: 0.3940\n","Epoch 153/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.4499 - acc: 0.4640 - val_loss: 1.6067 - val_acc: 0.3940\n","Epoch 154/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.5404 - acc: 0.4300 - val_loss: 1.6526 - val_acc: 0.3400\n","Epoch 155/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.4742 - acc: 0.4600 - val_loss: 1.5342 - val_acc: 0.4100\n","Epoch 156/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.4864 - acc: 0.4453"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 210us/step - loss: 1.4096 - acc: 0.4760 - val_loss: 1.5114 - val_acc: 0.4360\n","Epoch 157/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.3913 - acc: 0.4940 - val_loss: 1.5364 - val_acc: 0.4300\n","Epoch 158/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.4055 - acc: 0.4640 - val_loss: 1.6418 - val_acc: 0.3920\n","Epoch 159/500\n","500/500 [==============================] - 0s 250us/step - loss: 1.4823 - acc: 0.4300 - val_loss: 1.5522 - val_acc: 0.4240\n","Epoch 160/500\n","500/500 [==============================] - 0s 225us/step - loss: 1.3964 - acc: 0.4800 - val_loss: 1.5094 - val_acc: 0.4340\n","Epoch 161/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.3494 - acc: 0.5220 - val_loss: 1.5095 - val_acc: 0.4360\n","Epoch 162/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.3885 - acc: 0.4940 - val_loss: 1.6022 - val_acc: 0.4040\n","Epoch 163/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.5323 - acc: 0.4060 - val_loss: 1.5124 - val_acc: 0.4460\n","Epoch 164/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.3882 - acc: 0.4900 - val_loss: 1.5904 - val_acc: 0.3740\n","Epoch 165/500\n","500/500 [==============================] - 0s 224us/step - loss: 1.4065 - acc: 0.5200 - val_loss: 1.5070 - val_acc: 0.4220\n","Epoch 166/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3765 - acc: 0.5020 - val_loss: 1.5173 - val_acc: 0.4320\n","Epoch 167/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.3415 - acc: 0.5340 - val_loss: 1.5005 - val_acc: 0.4220\n","Epoch 168/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.3470 - acc: 0.4980 - val_loss: 1.5215 - val_acc: 0.4140\n","Epoch 169/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.3556 - acc: 0.4980 - val_loss: 1.4817 - val_acc: 0.4480\n","Epoch 170/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.4051 - acc: 0.4640 - val_loss: 1.6358 - val_acc: 0.3740\n","Epoch 171/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.3928 - acc: 0.4880 - val_loss: 1.4868 - val_acc: 0.4440\n","Epoch 172/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.3521 - acc: 0.4900 - val_loss: 1.4677 - val_acc: 0.4540\n","Epoch 173/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.3245 - acc: 0.5480 - val_loss: 1.5261 - val_acc: 0.4260\n","Epoch 174/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.4986 - acc: 0.4260 - val_loss: 1.5095 - val_acc: 0.4040\n","Epoch 175/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3720 - acc: 0.4940 - val_loss: 1.5350 - val_acc: 0.4060\n","Epoch 176/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3906 - acc: 0.4860 - val_loss: 1.4873 - val_acc: 0.4480\n","Epoch 177/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.3509 - acc: 0.4900 - val_loss: 1.4948 - val_acc: 0.4400\n","Epoch 178/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.3836 - acc: 0.5000 - val_loss: 1.4949 - val_acc: 0.4160\n","Epoch 179/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.4814 - acc: 0.4560 - val_loss: 1.5206 - val_acc: 0.4000\n","Epoch 180/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.3397 - acc: 0.5560 - val_loss: 1.4844 - val_acc: 0.4640\n","Epoch 181/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.3581 - acc: 0.5040 - val_loss: 1.4634 - val_acc: 0.4520\n","Epoch 182/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.2058 - acc: 0.5547"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 210us/step - loss: 1.3238 - acc: 0.5180 - val_loss: 1.4990 - val_acc: 0.4460\n","Epoch 183/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.3842 - acc: 0.4700 - val_loss: 1.4787 - val_acc: 0.4600\n","Epoch 184/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.3663 - acc: 0.4820 - val_loss: 1.5691 - val_acc: 0.4180\n","Epoch 185/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.3489 - acc: 0.4840 - val_loss: 1.4386 - val_acc: 0.4660\n","Epoch 186/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.2887 - acc: 0.5440 - val_loss: 1.5101 - val_acc: 0.4380\n","Epoch 187/500\n","500/500 [==============================] - 0s 224us/step - loss: 1.4035 - acc: 0.4620 - val_loss: 1.4847 - val_acc: 0.4580\n","Epoch 188/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.3254 - acc: 0.5280 - val_loss: 1.4543 - val_acc: 0.4700\n","Epoch 189/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.3112 - acc: 0.5020 - val_loss: 1.4286 - val_acc: 0.4660\n","Epoch 190/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.3044 - acc: 0.5320 - val_loss: 1.4612 - val_acc: 0.4700\n","Epoch 191/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.2722 - acc: 0.5360 - val_loss: 1.4440 - val_acc: 0.4620\n","Epoch 192/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.3286 - acc: 0.5380 - val_loss: 1.4741 - val_acc: 0.4600\n","Epoch 193/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.3147 - acc: 0.5140 - val_loss: 1.5126 - val_acc: 0.4020\n","Epoch 194/500\n","500/500 [==============================] - 0s 227us/step - loss: 1.4380 - acc: 0.4440 - val_loss: 1.4574 - val_acc: 0.4540\n","Epoch 195/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.3097 - acc: 0.5360 - val_loss: 1.5284 - val_acc: 0.4320\n","Epoch 196/500\n","500/500 [==============================] - 0s 225us/step - loss: 1.3040 - acc: 0.5160 - val_loss: 1.4464 - val_acc: 0.4760\n","Epoch 197/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.3206 - acc: 0.5200 - val_loss: 1.4116 - val_acc: 0.4880\n","Epoch 198/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.2969 - acc: 0.5200 - val_loss: 1.5218 - val_acc: 0.4560\n","Epoch 199/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.3593 - acc: 0.4920 - val_loss: 1.4053 - val_acc: 0.4760\n","Epoch 200/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.2716 - acc: 0.5480 - val_loss: 1.4211 - val_acc: 0.4780\n","Epoch 201/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.2294 - acc: 0.5420 - val_loss: 1.4545 - val_acc: 0.4720\n","Epoch 202/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.4012 - acc: 0.4580 - val_loss: 1.4304 - val_acc: 0.4680\n","Epoch 203/500\n","500/500 [==============================] - 0s 222us/step - loss: 1.2893 - acc: 0.5500 - val_loss: 1.4055 - val_acc: 0.4840\n","Epoch 204/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.2510 - acc: 0.5560 - val_loss: 1.4116 - val_acc: 0.4720\n","Epoch 205/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.2314 - acc: 0.5820 - val_loss: 1.4883 - val_acc: 0.4520\n","Epoch 206/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.2633 - acc: 0.5320 - val_loss: 1.4023 - val_acc: 0.4920\n","Epoch 207/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.2785 - acc: 0.5260 - val_loss: 1.3859 - val_acc: 0.4980\n","Epoch 208/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.1872 - acc: 0.5781"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 206us/step - loss: 1.3326 - acc: 0.4940 - val_loss: 1.4667 - val_acc: 0.4260\n","Epoch 209/500\n","500/500 [==============================] - 0s 227us/step - loss: 1.2996 - acc: 0.5000 - val_loss: 1.3938 - val_acc: 0.4840\n","Epoch 210/500\n","500/500 [==============================] - 0s 229us/step - loss: 1.2934 - acc: 0.5100 - val_loss: 1.4159 - val_acc: 0.4600\n","Epoch 211/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.2514 - acc: 0.6020 - val_loss: 1.3984 - val_acc: 0.4700\n","Epoch 212/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.2457 - acc: 0.5620 - val_loss: 1.3933 - val_acc: 0.4960\n","Epoch 213/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.2160 - acc: 0.5660 - val_loss: 1.3897 - val_acc: 0.4900\n","Epoch 214/500\n","500/500 [==============================] - 0s 225us/step - loss: 1.3498 - acc: 0.4860 - val_loss: 1.5480 - val_acc: 0.3860\n","Epoch 215/500\n","500/500 [==============================] - 0s 203us/step - loss: 1.3077 - acc: 0.5000 - val_loss: 1.3820 - val_acc: 0.5240\n","Epoch 216/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.3017 - acc: 0.5100 - val_loss: 1.4297 - val_acc: 0.4920\n","Epoch 217/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2144 - acc: 0.5880 - val_loss: 1.3669 - val_acc: 0.4960\n","Epoch 218/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2774 - acc: 0.5520 - val_loss: 1.3870 - val_acc: 0.4960\n","Epoch 219/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.2411 - acc: 0.5800 - val_loss: 1.3428 - val_acc: 0.5200\n","Epoch 220/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.2371 - acc: 0.5740 - val_loss: 1.4278 - val_acc: 0.4960\n","Epoch 221/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.3235 - acc: 0.5220 - val_loss: 1.4521 - val_acc: 0.4500\n","Epoch 222/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.2376 - acc: 0.5560 - val_loss: 1.3482 - val_acc: 0.5140\n","Epoch 223/500\n","500/500 [==============================] - 0s 223us/step - loss: 1.2567 - acc: 0.5820 - val_loss: 1.3740 - val_acc: 0.5000\n","Epoch 224/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.2377 - acc: 0.5660 - val_loss: 1.3561 - val_acc: 0.5220\n","Epoch 225/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2012 - acc: 0.5980 - val_loss: 1.3644 - val_acc: 0.4980\n","Epoch 226/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.2949 - acc: 0.5300 - val_loss: 1.3898 - val_acc: 0.4860\n","Epoch 227/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.3080 - acc: 0.5240 - val_loss: 1.4892 - val_acc: 0.4060\n","Epoch 228/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.2451 - acc: 0.5640 - val_loss: 1.3520 - val_acc: 0.5220\n","Epoch 229/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.2307 - acc: 0.5620 - val_loss: 1.4048 - val_acc: 0.4880\n","Epoch 230/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.3200 - acc: 0.4720 - val_loss: 1.3781 - val_acc: 0.5260\n","Epoch 231/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.2160 - acc: 0.5620 - val_loss: 1.3356 - val_acc: 0.5400\n","Epoch 232/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.1917 - acc: 0.5600 - val_loss: 1.3317 - val_acc: 0.5060\n","Epoch 233/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.1938 - acc: 0.5900 - val_loss: 1.3173 - val_acc: 0.5180\n","Epoch 234/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.0490 - acc: 0.6016"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 202us/step - loss: 1.2273 - acc: 0.5780 - val_loss: 1.3138 - val_acc: 0.5080\n","Epoch 235/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.2184 - acc: 0.5380 - val_loss: 1.4576 - val_acc: 0.4280\n","Epoch 236/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.2614 - acc: 0.5380 - val_loss: 1.3331 - val_acc: 0.5180\n","Epoch 237/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.2167 - acc: 0.5880 - val_loss: 1.3409 - val_acc: 0.5060\n","Epoch 238/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.1843 - acc: 0.5900 - val_loss: 1.3015 - val_acc: 0.5400\n","Epoch 239/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.2030 - acc: 0.5820 - val_loss: 1.3311 - val_acc: 0.5360\n","Epoch 240/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.1608 - acc: 0.5680 - val_loss: 1.3189 - val_acc: 0.5220\n","Epoch 241/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.1816 - acc: 0.5740 - val_loss: 1.3759 - val_acc: 0.5200\n","Epoch 242/500\n","500/500 [==============================] - 0s 225us/step - loss: 1.2779 - acc: 0.5240 - val_loss: 1.3612 - val_acc: 0.4900\n","Epoch 243/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2378 - acc: 0.5500 - val_loss: 1.3660 - val_acc: 0.5140\n","Epoch 244/500\n","500/500 [==============================] - 0s 231us/step - loss: 1.2942 - acc: 0.5180 - val_loss: 1.4180 - val_acc: 0.4760\n","Epoch 245/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.2327 - acc: 0.5620 - val_loss: 1.3352 - val_acc: 0.4980\n","Epoch 246/500\n","500/500 [==============================] - 0s 233us/step - loss: 1.1605 - acc: 0.5780 - val_loss: 1.3000 - val_acc: 0.5140\n","Epoch 247/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.2555 - acc: 0.5260 - val_loss: 1.4420 - val_acc: 0.4100\n","Epoch 248/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.3054 - acc: 0.4920 - val_loss: 1.3605 - val_acc: 0.4680\n","Epoch 249/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.2032 - acc: 0.5540 - val_loss: 1.3106 - val_acc: 0.5060\n","Epoch 250/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.1945 - acc: 0.5780 - val_loss: 1.2957 - val_acc: 0.5180\n","Epoch 251/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.2392 - acc: 0.5420 - val_loss: 1.3270 - val_acc: 0.5280\n","Epoch 252/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.1808 - acc: 0.5780 - val_loss: 1.4249 - val_acc: 0.4600\n","Epoch 253/500\n","500/500 [==============================] - 0s 221us/step - loss: 1.2234 - acc: 0.5400 - val_loss: 1.2892 - val_acc: 0.5660\n","Epoch 254/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.2026 - acc: 0.5700 - val_loss: 1.2699 - val_acc: 0.5440\n","Epoch 255/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.1387 - acc: 0.5980 - val_loss: 1.2902 - val_acc: 0.5220\n","Epoch 256/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.2217 - acc: 0.5660 - val_loss: 1.2624 - val_acc: 0.5540\n","Epoch 257/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.1342 - acc: 0.6080 - val_loss: 1.2956 - val_acc: 0.5460\n","Epoch 258/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.2106 - acc: 0.5840 - val_loss: 1.2510 - val_acc: 0.5780\n","Epoch 259/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.1349 - acc: 0.5740 - val_loss: 1.2802 - val_acc: 0.5500\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 260/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.1305 - acc: 0.5780 - val_loss: 1.3027 - val_acc: 0.5560\n","Epoch 261/500\n","500/500 [==============================] - 0s 220us/step - loss: 1.3128 - acc: 0.5040 - val_loss: 1.3572 - val_acc: 0.4780\n","Epoch 262/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.1300 - acc: 0.5820 - val_loss: 1.2684 - val_acc: 0.5460\n","Epoch 263/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.1980 - acc: 0.5720 - val_loss: 1.4369 - val_acc: 0.4280\n","Epoch 264/500\n","500/500 [==============================] - 0s 225us/step - loss: 1.1967 - acc: 0.5400 - val_loss: 1.2648 - val_acc: 0.5320\n","Epoch 265/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.1368 - acc: 0.5980 - val_loss: 1.3208 - val_acc: 0.5100\n","Epoch 266/500\n","500/500 [==============================] - 0s 221us/step - loss: 1.1209 - acc: 0.6060 - val_loss: 1.2444 - val_acc: 0.5300\n","Epoch 267/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.1611 - acc: 0.5660 - val_loss: 1.3563 - val_acc: 0.4600\n","Epoch 268/500\n","500/500 [==============================] - 0s 227us/step - loss: 1.1639 - acc: 0.6160 - val_loss: 1.2321 - val_acc: 0.5760\n","Epoch 269/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.1296 - acc: 0.6020 - val_loss: 1.3726 - val_acc: 0.4520\n","Epoch 270/500\n","500/500 [==============================] - 0s 242us/step - loss: 1.1695 - acc: 0.5800 - val_loss: 1.2680 - val_acc: 0.5200\n","Epoch 271/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.1253 - acc: 0.6080 - val_loss: 1.2771 - val_acc: 0.5140\n","Epoch 272/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.1438 - acc: 0.6020 - val_loss: 1.2576 - val_acc: 0.5180\n","Epoch 273/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.1014 - acc: 0.6180 - val_loss: 1.2454 - val_acc: 0.5580\n","Epoch 274/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.2075 - acc: 0.5460 - val_loss: 1.2918 - val_acc: 0.5400\n","Epoch 275/500\n","500/500 [==============================] - 0s 197us/step - loss: 1.1822 - acc: 0.5900 - val_loss: 1.2687 - val_acc: 0.5800\n","Epoch 276/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.1463 - acc: 0.6000 - val_loss: 1.2373 - val_acc: 0.5380\n","Epoch 277/500\n","500/500 [==============================] - 0s 194us/step - loss: 1.1022 - acc: 0.6320 - val_loss: 1.2736 - val_acc: 0.5400\n","Epoch 278/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.1169 - acc: 0.6220 - val_loss: 1.2122 - val_acc: 0.5500\n","Epoch 279/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0668 - acc: 0.6140 - val_loss: 1.2682 - val_acc: 0.5180\n","Epoch 280/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.0963 - acc: 0.5960 - val_loss: 1.2527 - val_acc: 0.5360\n","Epoch 281/500\n","500/500 [==============================] - 0s 193us/step - loss: 1.1626 - acc: 0.5840 - val_loss: 1.2461 - val_acc: 0.5680\n","Epoch 282/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.1822 - acc: 0.5920 - val_loss: 1.2482 - val_acc: 0.5660\n","Epoch 283/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.1095 - acc: 0.6080 - val_loss: 1.2030 - val_acc: 0.5900\n","Epoch 284/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.1402 - acc: 0.5640 - val_loss: 1.2013 - val_acc: 0.5720\n","Epoch 285/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.0733 - acc: 0.6300 - val_loss: 1.1902 - val_acc: 0.5900\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 286/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.0838 - acc: 0.6120 - val_loss: 1.2002 - val_acc: 0.5560\n","Epoch 287/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.1205 - acc: 0.5900 - val_loss: 1.3027 - val_acc: 0.5020\n","Epoch 288/500\n","500/500 [==============================] - 0s 212us/step - loss: 1.0732 - acc: 0.6300 - val_loss: 1.1910 - val_acc: 0.5760\n","Epoch 289/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.1348 - acc: 0.6040 - val_loss: 1.2041 - val_acc: 0.5920\n","Epoch 290/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.1835 - acc: 0.5700 - val_loss: 1.2188 - val_acc: 0.5800\n","Epoch 291/500\n","500/500 [==============================] - 0s 227us/step - loss: 1.0737 - acc: 0.6420 - val_loss: 1.1997 - val_acc: 0.5960\n","Epoch 292/500\n","500/500 [==============================] - 0s 202us/step - loss: 1.0615 - acc: 0.5860 - val_loss: 1.1786 - val_acc: 0.5960\n","Epoch 293/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.0563 - acc: 0.6340 - val_loss: 1.1711 - val_acc: 0.5800\n","Epoch 294/500\n","500/500 [==============================] - 0s 197us/step - loss: 1.0545 - acc: 0.6320 - val_loss: 1.3354 - val_acc: 0.4880\n","Epoch 295/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.1331 - acc: 0.5600 - val_loss: 1.2207 - val_acc: 0.5500\n","Epoch 296/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0410 - acc: 0.6480 - val_loss: 1.1640 - val_acc: 0.5980\n","Epoch 297/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.0751 - acc: 0.6300 - val_loss: 1.2266 - val_acc: 0.5620\n","Epoch 298/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.1147 - acc: 0.6040 - val_loss: 1.2020 - val_acc: 0.5560\n","Epoch 299/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.0306 - acc: 0.6440 - val_loss: 1.1880 - val_acc: 0.5460\n","Epoch 300/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.0440 - acc: 0.6360 - val_loss: 1.2332 - val_acc: 0.5380\n","Epoch 301/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.0643 - acc: 0.5960 - val_loss: 1.2131 - val_acc: 0.5420\n","Epoch 302/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.1542 - acc: 0.5840 - val_loss: 1.3481 - val_acc: 0.4700\n","Epoch 303/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.1163 - acc: 0.6040 - val_loss: 1.1817 - val_acc: 0.5620\n","Epoch 304/500\n","500/500 [==============================] - 0s 224us/step - loss: 1.0180 - acc: 0.6620 - val_loss: 1.2442 - val_acc: 0.5200\n","Epoch 305/500\n","500/500 [==============================] - 0s 198us/step - loss: 1.0840 - acc: 0.5980 - val_loss: 1.1771 - val_acc: 0.5560\n","Epoch 306/500\n","500/500 [==============================] - 0s 207us/step - loss: 1.0610 - acc: 0.6420 - val_loss: 1.1630 - val_acc: 0.5880\n","Epoch 307/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0506 - acc: 0.6360 - val_loss: 1.1754 - val_acc: 0.5460\n","Epoch 308/500\n","500/500 [==============================] - 0s 238us/step - loss: 1.0236 - acc: 0.6320 - val_loss: 1.2020 - val_acc: 0.5380\n","Epoch 309/500\n","500/500 [==============================] - 0s 199us/step - loss: 1.0457 - acc: 0.6220 - val_loss: 1.2040 - val_acc: 0.5400\n","Epoch 310/500\n","500/500 [==============================] - 0s 234us/step - loss: 1.0330 - acc: 0.6760 - val_loss: 1.1801 - val_acc: 0.5520\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 311/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0832 - acc: 0.6160 - val_loss: 1.3228 - val_acc: 0.5040\n","Epoch 312/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.1239 - acc: 0.5920 - val_loss: 1.2614 - val_acc: 0.5260\n","Epoch 313/500\n","500/500 [==============================] - 0s 218us/step - loss: 1.1770 - acc: 0.5640 - val_loss: 1.2558 - val_acc: 0.5200\n","Epoch 314/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0932 - acc: 0.6300 - val_loss: 1.2760 - val_acc: 0.5100\n","Epoch 315/500\n","500/500 [==============================] - 0s 206us/step - loss: 1.0083 - acc: 0.6240 - val_loss: 1.1655 - val_acc: 0.5500\n","Epoch 316/500\n","500/500 [==============================] - 0s 196us/step - loss: 1.1017 - acc: 0.6060 - val_loss: 1.2158 - val_acc: 0.5360\n","Epoch 317/500\n","500/500 [==============================] - 0s 205us/step - loss: 1.0417 - acc: 0.6500 - val_loss: 1.1732 - val_acc: 0.5860\n","Epoch 318/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.0383 - acc: 0.6440 - val_loss: 1.1682 - val_acc: 0.5700\n","Epoch 319/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.0444 - acc: 0.6260 - val_loss: 1.1554 - val_acc: 0.5900\n","Epoch 320/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.0160 - acc: 0.6560 - val_loss: 1.2050 - val_acc: 0.5500\n","Epoch 321/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0477 - acc: 0.6320 - val_loss: 1.1186 - val_acc: 0.6140\n","Epoch 322/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0141 - acc: 0.6440 - val_loss: 1.1706 - val_acc: 0.5580\n","Epoch 323/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.0293 - acc: 0.6600 - val_loss: 1.1506 - val_acc: 0.5980\n","Epoch 324/500\n","500/500 [==============================] - 0s 213us/step - loss: 1.1265 - acc: 0.5720 - val_loss: 1.2053 - val_acc: 0.5740\n","Epoch 325/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.0430 - acc: 0.6220 - val_loss: 1.1606 - val_acc: 0.5980\n","Epoch 326/500\n","500/500 [==============================] - 0s 209us/step - loss: 1.0079 - acc: 0.6560 - val_loss: 1.1167 - val_acc: 0.5880\n","Epoch 327/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.9841 - acc: 0.6420 - val_loss: 1.1393 - val_acc: 0.6080\n","Epoch 328/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9875 - acc: 0.6680 - val_loss: 1.1545 - val_acc: 0.5660\n","Epoch 329/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.9926 - acc: 0.6680 - val_loss: 1.1415 - val_acc: 0.5880\n","Epoch 330/500\n","500/500 [==============================] - 0s 204us/step - loss: 1.0781 - acc: 0.6080 - val_loss: 1.1917 - val_acc: 0.5500\n","Epoch 331/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.0509 - acc: 0.6240 - val_loss: 1.1371 - val_acc: 0.5900\n","Epoch 332/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9995 - acc: 0.6580 - val_loss: 1.3076 - val_acc: 0.4880\n","Epoch 333/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.0990 - acc: 0.6080 - val_loss: 1.2363 - val_acc: 0.5240\n","Epoch 334/500\n","500/500 [==============================] - 0s 201us/step - loss: 1.0688 - acc: 0.6360 - val_loss: 1.1290 - val_acc: 0.5920\n","Epoch 335/500\n","500/500 [==============================] - 0s 216us/step - loss: 1.0117 - acc: 0.6440 - val_loss: 1.1176 - val_acc: 0.6100\n","Epoch 336/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9668 - acc: 0.6540 - val_loss: 1.1130 - val_acc: 0.5880\n","Epoch 337/500\n","128/500 [======>.......................] - ETA: 0s - loss: 1.0785 - acc: 0.6484"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 211us/step - loss: 0.9950 - acc: 0.6600 - val_loss: 1.2430 - val_acc: 0.5560\n","Epoch 338/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.9926 - acc: 0.6540 - val_loss: 1.1001 - val_acc: 0.6040\n","Epoch 339/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.9815 - acc: 0.6800 - val_loss: 1.1146 - val_acc: 0.6140\n","Epoch 340/500\n","500/500 [==============================] - 0s 200us/step - loss: 1.0831 - acc: 0.6340 - val_loss: 1.2199 - val_acc: 0.5460\n","Epoch 341/500\n","500/500 [==============================] - 0s 210us/step - loss: 1.0010 - acc: 0.6600 - val_loss: 1.1145 - val_acc: 0.5900\n","Epoch 342/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.9534 - acc: 0.6780 - val_loss: 1.0887 - val_acc: 0.6340\n","Epoch 343/500\n","500/500 [==============================] - 0s 217us/step - loss: 1.0079 - acc: 0.6340 - val_loss: 1.1421 - val_acc: 0.5860\n","Epoch 344/500\n","500/500 [==============================] - 0s 196us/step - loss: 1.0261 - acc: 0.6320 - val_loss: 1.1053 - val_acc: 0.6020\n","Epoch 345/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9802 - acc: 0.6620 - val_loss: 1.0913 - val_acc: 0.6160\n","Epoch 346/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.9987 - acc: 0.6520 - val_loss: 1.0909 - val_acc: 0.6200\n","Epoch 347/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9499 - acc: 0.6680 - val_loss: 1.0944 - val_acc: 0.5940\n","Epoch 348/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.9990 - acc: 0.6600 - val_loss: 1.1576 - val_acc: 0.5880\n","Epoch 349/500\n","500/500 [==============================] - 0s 215us/step - loss: 1.0191 - acc: 0.6620 - val_loss: 1.0987 - val_acc: 0.6100\n","Epoch 350/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.9545 - acc: 0.6660 - val_loss: 1.2076 - val_acc: 0.5260\n","Epoch 351/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.9327 - acc: 0.6700 - val_loss: 1.1162 - val_acc: 0.5740\n","Epoch 352/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9314 - acc: 0.6740 - val_loss: 1.0891 - val_acc: 0.6140\n","Epoch 353/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.9734 - acc: 0.6720 - val_loss: 1.2366 - val_acc: 0.5400\n","Epoch 354/500\n","500/500 [==============================] - 0s 208us/step - loss: 1.0070 - acc: 0.6340 - val_loss: 1.1094 - val_acc: 0.6060\n","Epoch 355/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.9377 - acc: 0.6780 - val_loss: 1.1103 - val_acc: 0.6040\n","Epoch 356/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9907 - acc: 0.6520 - val_loss: 1.1059 - val_acc: 0.5940\n","Epoch 357/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.9551 - acc: 0.6800 - val_loss: 1.1179 - val_acc: 0.5840\n","Epoch 358/500\n","500/500 [==============================] - 0s 219us/step - loss: 1.0008 - acc: 0.6420 - val_loss: 1.0695 - val_acc: 0.6100\n","Epoch 359/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.9430 - acc: 0.6700 - val_loss: 1.0849 - val_acc: 0.6020\n","Epoch 360/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.9264 - acc: 0.6840 - val_loss: 1.0690 - val_acc: 0.6240\n","Epoch 361/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9249 - acc: 0.6740 - val_loss: 1.1847 - val_acc: 0.5320\n","Epoch 362/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.9455 - acc: 0.6780 - val_loss: 1.0442 - val_acc: 0.6300\n","Epoch 363/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.8646 - acc: 0.7188"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 203us/step - loss: 0.9388 - acc: 0.6960 - val_loss: 1.0554 - val_acc: 0.6060\n","Epoch 364/500\n","500/500 [==============================] - 0s 233us/step - loss: 0.9299 - acc: 0.6720 - val_loss: 1.1254 - val_acc: 0.5820\n","Epoch 365/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.9625 - acc: 0.6740 - val_loss: 1.1159 - val_acc: 0.6000\n","Epoch 366/500\n","500/500 [==============================] - 0s 214us/step - loss: 1.0242 - acc: 0.6220 - val_loss: 1.0582 - val_acc: 0.6320\n","Epoch 367/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9211 - acc: 0.6940 - val_loss: 1.0821 - val_acc: 0.6080\n","Epoch 368/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.9536 - acc: 0.6980 - val_loss: 1.0602 - val_acc: 0.6240\n","Epoch 369/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.9859 - acc: 0.6300 - val_loss: 1.0664 - val_acc: 0.6220\n","Epoch 370/500\n","500/500 [==============================] - 0s 222us/step - loss: 0.9548 - acc: 0.6560 - val_loss: 1.1555 - val_acc: 0.5960\n","Epoch 371/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9153 - acc: 0.6940 - val_loss: 1.0651 - val_acc: 0.5880\n","Epoch 372/500\n","500/500 [==============================] - 0s 193us/step - loss: 0.8953 - acc: 0.7060 - val_loss: 1.0402 - val_acc: 0.6340\n","Epoch 373/500\n","500/500 [==============================] - 0s 222us/step - loss: 0.9332 - acc: 0.6680 - val_loss: 1.0477 - val_acc: 0.6320\n","Epoch 374/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.9187 - acc: 0.7020 - val_loss: 1.0355 - val_acc: 0.6340\n","Epoch 375/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9090 - acc: 0.6920 - val_loss: 1.0522 - val_acc: 0.6340\n","Epoch 376/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.9377 - acc: 0.6880 - val_loss: 1.0954 - val_acc: 0.5860\n","Epoch 377/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.9887 - acc: 0.6420 - val_loss: 1.0529 - val_acc: 0.6280\n","Epoch 378/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.9006 - acc: 0.6740 - val_loss: 1.1200 - val_acc: 0.5720\n","Epoch 379/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9594 - acc: 0.6740 - val_loss: 1.1502 - val_acc: 0.5580\n","Epoch 380/500\n","500/500 [==============================] - 0s 198us/step - loss: 0.8886 - acc: 0.6640 - val_loss: 1.0451 - val_acc: 0.6200\n","Epoch 381/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.9334 - acc: 0.6880 - val_loss: 1.0570 - val_acc: 0.5960\n","Epoch 382/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.9241 - acc: 0.6800 - val_loss: 1.0434 - val_acc: 0.6160\n","Epoch 383/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.9302 - acc: 0.6620 - val_loss: 1.0782 - val_acc: 0.6220\n","Epoch 384/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.8666 - acc: 0.7220 - val_loss: 1.0988 - val_acc: 0.5900\n","Epoch 385/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.9243 - acc: 0.6600 - val_loss: 1.0316 - val_acc: 0.6160\n","Epoch 386/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.9668 - acc: 0.6500 - val_loss: 1.1663 - val_acc: 0.5600\n","Epoch 387/500\n","500/500 [==============================] - 0s 225us/step - loss: 0.9278 - acc: 0.6720 - val_loss: 1.0207 - val_acc: 0.6260\n","Epoch 388/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8718 - acc: 0.6740 - val_loss: 1.0198 - val_acc: 0.6420\n","Epoch 389/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.9640 - acc: 0.6562"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 218us/step - loss: 0.9140 - acc: 0.6880 - val_loss: 1.1670 - val_acc: 0.5780\n","Epoch 390/500\n","500/500 [==============================] - 0s 211us/step - loss: 1.0336 - acc: 0.6340 - val_loss: 1.0294 - val_acc: 0.6440\n","Epoch 391/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.8808 - acc: 0.7060 - val_loss: 1.0198 - val_acc: 0.6320\n","Epoch 392/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.8483 - acc: 0.7060 - val_loss: 1.0560 - val_acc: 0.5980\n","Epoch 393/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.9133 - acc: 0.6660 - val_loss: 1.0213 - val_acc: 0.6440\n","Epoch 394/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.9365 - acc: 0.6880 - val_loss: 1.1193 - val_acc: 0.5640\n","Epoch 395/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.9704 - acc: 0.6820 - val_loss: 1.0938 - val_acc: 0.5840\n","Epoch 396/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.8518 - acc: 0.7080 - val_loss: 1.0178 - val_acc: 0.6480\n","Epoch 397/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.8789 - acc: 0.7060 - val_loss: 1.0244 - val_acc: 0.6440\n","Epoch 398/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.9043 - acc: 0.6820 - val_loss: 1.0000 - val_acc: 0.6440\n","Epoch 399/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.8795 - acc: 0.6900 - val_loss: 1.0124 - val_acc: 0.6460\n","Epoch 400/500\n","500/500 [==============================] - 0s 220us/step - loss: 0.8281 - acc: 0.7300 - val_loss: 0.9981 - val_acc: 0.6380\n","Epoch 401/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.8738 - acc: 0.7060 - val_loss: 1.0260 - val_acc: 0.6420\n","Epoch 402/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.8723 - acc: 0.6980 - val_loss: 1.0475 - val_acc: 0.6060\n","Epoch 403/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.9258 - acc: 0.6700 - val_loss: 0.9918 - val_acc: 0.6540\n","Epoch 404/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.8455 - acc: 0.7140 - val_loss: 1.0994 - val_acc: 0.5760\n","Epoch 405/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.9113 - acc: 0.6780 - val_loss: 1.0542 - val_acc: 0.6000\n","Epoch 406/500\n","500/500 [==============================] - 0s 219us/step - loss: 0.8768 - acc: 0.7120 - val_loss: 1.0596 - val_acc: 0.6040\n","Epoch 407/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8559 - acc: 0.7060 - val_loss: 1.0091 - val_acc: 0.6400\n","Epoch 408/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8585 - acc: 0.7040 - val_loss: 1.0388 - val_acc: 0.6280\n","Epoch 409/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.8446 - acc: 0.7320 - val_loss: 1.0424 - val_acc: 0.6220\n","Epoch 410/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.8155 - acc: 0.7140 - val_loss: 0.9871 - val_acc: 0.6420\n","Epoch 411/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8560 - acc: 0.7180 - val_loss: 1.0210 - val_acc: 0.6120\n","Epoch 412/500\n","500/500 [==============================] - 0s 230us/step - loss: 0.9905 - acc: 0.6420 - val_loss: 1.0371 - val_acc: 0.5980\n","Epoch 413/500\n","500/500 [==============================] - 0s 199us/step - loss: 0.8801 - acc: 0.7020 - val_loss: 1.0407 - val_acc: 0.6240\n","Epoch 414/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.8679 - acc: 0.7266"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 211us/step - loss: 0.8537 - acc: 0.6940 - val_loss: 0.9848 - val_acc: 0.6400\n","Epoch 415/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8619 - acc: 0.7100 - val_loss: 0.9929 - val_acc: 0.6460\n","Epoch 416/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.8824 - acc: 0.6960 - val_loss: 1.0224 - val_acc: 0.6180\n","Epoch 417/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.8303 - acc: 0.7160 - val_loss: 0.9819 - val_acc: 0.6400\n","Epoch 418/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.8166 - acc: 0.7180 - val_loss: 0.9649 - val_acc: 0.6600\n","Epoch 419/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.8434 - acc: 0.7280 - val_loss: 1.1026 - val_acc: 0.5840\n","Epoch 420/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.8589 - acc: 0.6720 - val_loss: 1.0625 - val_acc: 0.6000\n","Epoch 421/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.8610 - acc: 0.6940 - val_loss: 1.0060 - val_acc: 0.6300\n","Epoch 422/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.8580 - acc: 0.7140 - val_loss: 0.9834 - val_acc: 0.6340\n","Epoch 423/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.8675 - acc: 0.6880 - val_loss: 1.1485 - val_acc: 0.5500\n","Epoch 424/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.9262 - acc: 0.6880 - val_loss: 0.9899 - val_acc: 0.6540\n","Epoch 425/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.8435 - acc: 0.6940 - val_loss: 1.0093 - val_acc: 0.6500\n","Epoch 426/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.8416 - acc: 0.7260 - val_loss: 1.0428 - val_acc: 0.5940\n","Epoch 427/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.9056 - acc: 0.6980 - val_loss: 0.9706 - val_acc: 0.6600\n","Epoch 428/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.8078 - acc: 0.7180 - val_loss: 0.9630 - val_acc: 0.6480\n","Epoch 429/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.8310 - acc: 0.7060 - val_loss: 0.9821 - val_acc: 0.6480\n","Epoch 430/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.8201 - acc: 0.7200 - val_loss: 0.9800 - val_acc: 0.6660\n","Epoch 431/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.8918 - acc: 0.6940 - val_loss: 0.9740 - val_acc: 0.6660\n","Epoch 432/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.8804 - acc: 0.6920 - val_loss: 1.0407 - val_acc: 0.5980\n","Epoch 433/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.8716 - acc: 0.7020 - val_loss: 1.0175 - val_acc: 0.6160\n","Epoch 434/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.8412 - acc: 0.7020 - val_loss: 0.9931 - val_acc: 0.6360\n","Epoch 435/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.8039 - acc: 0.7120 - val_loss: 0.9516 - val_acc: 0.6700\n","Epoch 436/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.9026 - acc: 0.6960 - val_loss: 0.9749 - val_acc: 0.6580\n","Epoch 437/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.8292 - acc: 0.7200 - val_loss: 1.0314 - val_acc: 0.6380\n","Epoch 438/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.8529 - acc: 0.6740 - val_loss: 1.0262 - val_acc: 0.6420\n","Epoch 439/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.7961 - acc: 0.7300 - val_loss: 0.9885 - val_acc: 0.6320\n","Epoch 440/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.7394 - acc: 0.7734"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 207us/step - loss: 0.8332 - acc: 0.7300 - val_loss: 0.9917 - val_acc: 0.6420\n","Epoch 441/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8070 - acc: 0.7040 - val_loss: 0.9544 - val_acc: 0.6700\n","Epoch 442/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.7929 - acc: 0.7300 - val_loss: 0.9785 - val_acc: 0.6300\n","Epoch 443/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.8243 - acc: 0.6980 - val_loss: 0.9948 - val_acc: 0.6280\n","Epoch 444/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.8499 - acc: 0.7180 - val_loss: 0.9568 - val_acc: 0.6760\n","Epoch 445/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8497 - acc: 0.7100 - val_loss: 0.9657 - val_acc: 0.6700\n","Epoch 446/500\n","500/500 [==============================] - 0s 196us/step - loss: 0.8026 - acc: 0.7420 - val_loss: 0.9732 - val_acc: 0.6540\n","Epoch 447/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.8113 - acc: 0.7420 - val_loss: 0.9410 - val_acc: 0.6500\n","Epoch 448/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.8195 - acc: 0.6980 - val_loss: 0.9924 - val_acc: 0.6180\n","Epoch 449/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.8451 - acc: 0.7100 - val_loss: 1.0285 - val_acc: 0.6140\n","Epoch 450/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.8097 - acc: 0.7280 - val_loss: 0.9830 - val_acc: 0.6540\n","Epoch 451/500\n","500/500 [==============================] - 0s 205us/step - loss: 0.8072 - acc: 0.7180 - val_loss: 0.9420 - val_acc: 0.6580\n","Epoch 452/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8242 - acc: 0.6960 - val_loss: 1.0148 - val_acc: 0.6080\n","Epoch 453/500\n","500/500 [==============================] - 0s 216us/step - loss: 0.7907 - acc: 0.7280 - val_loss: 1.1136 - val_acc: 0.5720\n","Epoch 454/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.8486 - acc: 0.6900 - val_loss: 1.0243 - val_acc: 0.6340\n","Epoch 455/500\n","500/500 [==============================] - 0s 223us/step - loss: 0.7613 - acc: 0.7320 - val_loss: 0.9619 - val_acc: 0.6660\n","Epoch 456/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.8646 - acc: 0.7120 - val_loss: 1.0090 - val_acc: 0.6440\n","Epoch 457/500\n","500/500 [==============================] - 0s 229us/step - loss: 0.7935 - acc: 0.7260 - val_loss: 0.9689 - val_acc: 0.6620\n","Epoch 458/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.7573 - acc: 0.7600 - val_loss: 0.9855 - val_acc: 0.6320\n","Epoch 459/500\n","500/500 [==============================] - 0s 218us/step - loss: 0.8118 - acc: 0.7260 - val_loss: 1.0199 - val_acc: 0.6020\n","Epoch 460/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8165 - acc: 0.7120 - val_loss: 1.0329 - val_acc: 0.6160\n","Epoch 461/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.8804 - acc: 0.6840 - val_loss: 0.9445 - val_acc: 0.6460\n","Epoch 462/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.7778 - acc: 0.7220 - val_loss: 0.9351 - val_acc: 0.6680\n","Epoch 463/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.8643 - acc: 0.7120 - val_loss: 0.9483 - val_acc: 0.6680\n","Epoch 464/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.7550 - acc: 0.7380 - val_loss: 0.9630 - val_acc: 0.6340\n","Epoch 465/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.7611 - acc: 0.7500 - val_loss: 0.9396 - val_acc: 0.6640\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 466/500\n","500/500 [==============================] - 0s 197us/step - loss: 0.9038 - acc: 0.6780 - val_loss: 1.0319 - val_acc: 0.6480\n","Epoch 467/500\n","500/500 [==============================] - 0s 220us/step - loss: 0.8390 - acc: 0.7060 - val_loss: 0.9549 - val_acc: 0.6620\n","Epoch 468/500\n","500/500 [==============================] - 0s 206us/step - loss: 0.7906 - acc: 0.7220 - val_loss: 0.9428 - val_acc: 0.6480\n","Epoch 469/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.7389 - acc: 0.7720 - val_loss: 0.9588 - val_acc: 0.6600\n","Epoch 470/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7833 - acc: 0.7060 - val_loss: 0.9290 - val_acc: 0.6860\n","Epoch 471/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.7622 - acc: 0.7300 - val_loss: 0.9520 - val_acc: 0.6620\n","Epoch 472/500\n","500/500 [==============================] - 0s 213us/step - loss: 0.8147 - acc: 0.7040 - val_loss: 1.0220 - val_acc: 0.6380\n","Epoch 473/500\n","500/500 [==============================] - 0s 210us/step - loss: 0.7919 - acc: 0.7220 - val_loss: 0.9902 - val_acc: 0.6160\n","Epoch 474/500\n","500/500 [==============================] - 0s 215us/step - loss: 0.8120 - acc: 0.7140 - val_loss: 0.9691 - val_acc: 0.6300\n","Epoch 475/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.8008 - acc: 0.7320 - val_loss: 1.0453 - val_acc: 0.6020\n","Epoch 476/500\n","500/500 [==============================] - 0s 220us/step - loss: 0.8471 - acc: 0.7140 - val_loss: 0.9905 - val_acc: 0.6340\n","Epoch 477/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7758 - acc: 0.7440 - val_loss: 0.9278 - val_acc: 0.6760\n","Epoch 478/500\n","500/500 [==============================] - 0s 218us/step - loss: 0.7669 - acc: 0.7400 - val_loss: 0.9220 - val_acc: 0.6840\n","Epoch 479/500\n","500/500 [==============================] - 0s 214us/step - loss: 0.7517 - acc: 0.7460 - val_loss: 1.0356 - val_acc: 0.6320\n","Epoch 480/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.7959 - acc: 0.7120 - val_loss: 0.9384 - val_acc: 0.6640\n","Epoch 481/500\n","500/500 [==============================] - 0s 208us/step - loss: 0.7287 - acc: 0.7260 - val_loss: 0.9177 - val_acc: 0.6760\n","Epoch 482/500\n","500/500 [==============================] - 0s 221us/step - loss: 0.7283 - acc: 0.7400 - val_loss: 0.9231 - val_acc: 0.6780\n","Epoch 483/500\n","500/500 [==============================] - 0s 200us/step - loss: 0.7715 - acc: 0.7320 - val_loss: 1.0236 - val_acc: 0.6040\n","Epoch 484/500\n","500/500 [==============================] - 0s 203us/step - loss: 0.7322 - acc: 0.7440 - val_loss: 0.9079 - val_acc: 0.6600\n","Epoch 485/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.7416 - acc: 0.7300 - val_loss: 0.9267 - val_acc: 0.6700\n","Epoch 486/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7143 - acc: 0.7640 - val_loss: 0.9113 - val_acc: 0.6820\n","Epoch 487/500\n","500/500 [==============================] - 0s 207us/step - loss: 0.7895 - acc: 0.7340 - val_loss: 1.0667 - val_acc: 0.6080\n","Epoch 488/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.8102 - acc: 0.7020 - val_loss: 0.9599 - val_acc: 0.6560\n","Epoch 489/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.7772 - acc: 0.7280 - val_loss: 0.9994 - val_acc: 0.6140\n","Epoch 490/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7426 - acc: 0.7660 - val_loss: 0.9439 - val_acc: 0.6700\n","Epoch 491/500\n","500/500 [==============================] - 0s 202us/step - loss: 0.7567 - acc: 0.7240 - val_loss: 0.9731 - val_acc: 0.6540\n","Epoch 492/500\n","128/500 [======>.......................] - ETA: 0s - loss: 0.8045 - acc: 0.7188"],"name":"stdout"},{"output_type":"stream","text":["500/500 [==============================] - 0s 204us/step - loss: 0.7889 - acc: 0.7320 - val_loss: 0.9086 - val_acc: 0.6780\n","Epoch 493/500\n","500/500 [==============================] - 0s 201us/step - loss: 0.7557 - acc: 0.7400 - val_loss: 0.9527 - val_acc: 0.6700\n","Epoch 494/500\n","500/500 [==============================] - 0s 217us/step - loss: 0.8356 - acc: 0.6720 - val_loss: 0.9048 - val_acc: 0.6760\n","Epoch 495/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7765 - acc: 0.7200 - val_loss: 0.9208 - val_acc: 0.6740\n","Epoch 496/500\n","500/500 [==============================] - 0s 223us/step - loss: 0.7207 - acc: 0.7540 - val_loss: 0.9104 - val_acc: 0.6800\n","Epoch 497/500\n","500/500 [==============================] - 0s 209us/step - loss: 0.7324 - acc: 0.7620 - val_loss: 0.9299 - val_acc: 0.6760\n","Epoch 498/500\n","500/500 [==============================] - 0s 211us/step - loss: 0.7781 - acc: 0.7400 - val_loss: 0.8990 - val_acc: 0.6820\n","Epoch 499/500\n","500/500 [==============================] - 0s 212us/step - loss: 0.7364 - acc: 0.7420 - val_loss: 0.9985 - val_acc: 0.6280\n","Epoch 500/500\n","500/500 [==============================] - 0s 204us/step - loss: 0.7561 - acc: 0.7300 - val_loss: 0.9600 - val_acc: 0.6560\n","Test loss: 0.9599669947624206\n","Test accuracy: 0.6559999995231628\n"],"name":"stdout"}]},{"metadata":{"id":"zJ0ZI0AAi1BY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}