{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet50画像分類の推定処理.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"gkSRydvxm52Z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":11}],"base_uri":"https://localhost:8080/","height":538},"outputId":"31fcc588-fe6c-40ca-cc37-d3d52c56168e","executionInfo":{"status":"ok","timestamp":1520915202718,"user_tz":-540,"elapsed":4709,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["!pip install Keras==2.0.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting Keras==2.0.0\n","  Downloading Keras-2.0.0.tar.gz (191kB)\n","\u001b[K    100% |████████████████████████████████| 194kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from Keras==2.0.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: tensorboard<1.7.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->Keras==2.0.0)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow->Keras==2.0.0)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.4.0->tensorflow->Keras==2.0.0)\n","Building wheels for collected packages: Keras\n","  Running setup.py bdist_wheel for Keras ... \u001b[?25l-\b \b\\\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/02/88/e7/d2bb6fa8b26ab2966bcaa00d25c0d0052bb2f8e15b5445515b\n","Successfully built Keras\n","Installing collected packages: Keras\n","  Found existing installation: Keras 2.1.5\n","    Uninstalling Keras-2.1.5:\n","      Successfully uninstalled Keras-2.1.5\n","Successfully installed Keras-2.0.0\n"],"name":"stdout"}]},{"metadata":{"id":"5Jw_-GgKm85N","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"12aee077-df38-41d4-c28b-6681c8275a1f","executionInfo":{"status":"ok","timestamp":1520915249725,"user_tz":-540,"elapsed":7586,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["import numpy as np\n","import warnings\n","\n","from keras.layers import Input\n","from keras import layers\n","from keras.layers import Dense\n","from keras.layers import Activation\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import GlobalMaxPooling2D\n","from keras.layers import ZeroPadding2D\n","from keras.layers import AveragePooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras.layers import BatchNormalization\n","from keras.models import Model\n","from keras.preprocessing import image\n","import keras.backend as K\n","from keras.utils import layer_utils\n","from keras.utils.data_utils import get_file\n","from keras.applications.imagenet_utils import decode_predictions\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.applications.imagenet_utils import _obtain_input_shape\n","from keras.engine.topology import get_source_inputs\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"emRFxaPInNxm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":4}],"base_uri":"https://localhost:8080/","height":313},"outputId":"8e1dc921-263c-4430-e81b-7bd8772af8e3","executionInfo":{"status":"ok","timestamp":1520915371337,"user_tz":-540,"elapsed":2159,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n","WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","!wget https://www.dropbox.com/s/mmatzj3k5cj5rak/Horton-the-Elephant.png"],"execution_count":8,"outputs":[{"output_type":"stream","text":["--2018-03-13 04:29:27--  https://www.dropbox.com/s/mmatzj3k5cj5rak/Horton-the-Elephant.png\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6031:1::a27d:5101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://dl.dropboxusercontent.com/content_link/83dC82rModHZ9Teymv74nB4SyBImNiewS8CmRNJXGQc2o7RpH0IHAjbfBy4G9ylk/file [following]\n","--2018-03-13 04:29:27--  https://dl.dropboxusercontent.com/content_link/83dC82rModHZ9Teymv74nB4SyBImNiewS8CmRNJXGQc2o7RpH0IHAjbfBy4G9ylk/file\n","Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.6.6, 2620:100:601c:6::a27d:606\n","Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.6.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1580732 (1.5M) [image/png]\n","Saving to: ‘Horton-the-Elephant.png’\n","\n","Horton-the-Elephant 100%[===================>]   1.51M  --.-KB/s    in 0.08s   \n","\n","2018-03-13 04:29:28 (19.3 MB/s) - ‘Horton-the-Elephant.png’ saved [1580732/1580732]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"-VmswU6cnQvq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def identity_block(input_tensor, kernel_size, filters, stage, block):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size,\n","               padding='same', name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","\n","    x = layers.add([x, input_tensor])\n","    x = Activation('relu')(x)\n","    return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JSY2p8_JnWgS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), strides=strides,\n","               name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size, padding='same',\n","               name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","\n","    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n","                      name=conv_name_base + '1')(input_tensor)\n","    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n","\n","    x = layers.add([x, shortcut])\n","    x = Activation('relu')(x)\n","    return x\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zq3Azjk9nccb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def ResNet50(include_top=True, weights='imagenet',\n","             input_tensor=None, input_shape=None,\n","             pooling=None,\n","             classes=1000):\n","    if weights not in {'imagenet', None}:\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization) or `imagenet` '\n","                         '(pre-training on ImageNet).')\n","\n","    if weights == 'imagenet' and include_top and classes != 1000:\n","        raise ValueError('If using `weights` as imagenet with `include_top`'\n","                         ' as true, `classes` should be 1000')\n","\n","    # Determine proper input shape\n","    input_shape = _obtain_input_shape(input_shape,\n","                                      default_size=224,\n","                                      min_size=197,\n","                                      data_format=K.image_data_format(),\n","                                      include_top=include_top)\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","\n","    x = ZeroPadding2D((3, 3))(img_input)\n","    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n","    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n","\n","    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n","\n","    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n","\n","    if include_top:\n","        x = Flatten()(x)\n","        x = Dense(classes, activation='softmax', name='fc1000')(x)\n","    else:\n","        if pooling == 'avg':\n","            x = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            x = GlobalMaxPooling2D()(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","    # Create model.\n","    model = Model(inputs, x, name='resnet50')\n","\n","    # load weights\n","    if weights == 'imagenet':\n","        if include_top:\n","            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n","                                    WEIGHTS_PATH,\n","                                    cache_subdir='models',\n","                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n","        else:\n","            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","                                    WEIGHTS_PATH_NO_TOP,\n","                                    cache_subdir='models',\n","                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n","        model.load_weights(weights_path)\n","        if K.backend() == 'theano':\n","            layer_utils.convert_all_kernels_in_model(model)\n","\n","        if K.image_data_format() == 'channels_first':\n","            if include_top:\n","                maxpool = model.get_layer(name='avg_pool')\n","                shape = maxpool.output_shape[1:]\n","                dense = model.get_layer(name='fc1000')\n","                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n","\n","            if K.backend() == 'tensorflow':\n","                warnings.warn('You are using the TensorFlow backend, yet you '\n","                              'are using the Theano '\n","                              'image data format convention '\n","                              '(`image_data_format=\"channels_first\"`). '\n","                              'For best performance, set '\n","                              '`image_data_format=\"channels_last\"` in '\n","                              'your Keras config '\n","                              'at ~/.keras/keras.json.')\n","    return model\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ogvdZl3nnihh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":3}],"base_uri":"https://localhost:8080/","height":106},"outputId":"094bc2f6-628d-4397-8728-83fdf1bc2221","executionInfo":{"status":"ok","timestamp":1520915567912,"user_tz":-540,"elapsed":9891,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["if __name__ == '__main__':\n","    model = ResNet50(include_top=True, weights='imagenet')\n","\n","    img_path = 'Horton-the-Elephant.png'\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    print('Input image shape:', x.shape)\n","\n","    preds = model.predict(x)\n","    print('Predicted:', decode_predictions(preds))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","Input image shape: (1, 224, 224, 3)\n","Downloading data from https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n","Predicted: [[('n02841315', 'binoculars', 0.107181594), ('n02504013', 'Indian_elephant', 0.089639105), ('n02412080', 'ram', 0.08123497), ('n02415577', 'bighorn', 0.03169293), ('n02124075', 'Egyptian_cat', 0.027336465)]]\n"],"name":"stdout"}]},{"metadata":{"id":"j0hUabnNnkhJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}