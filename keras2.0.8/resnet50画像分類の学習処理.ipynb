{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet50画像分類の学習処理.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"WW4WwEMNHU6M","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":5}],"base_uri":"https://localhost:8080/","height":224},"outputId":"d02e8ffe-b903-4399-cc3f-0b6ee1395386","executionInfo":{"status":"ok","timestamp":1522130183398,"user_tz":-540,"elapsed":2757,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["!pip install Keras==2.1.5"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting Keras==2.1.5\n","  Downloading Keras-2.1.5-py2.py3-none-any.whl (334kB)\n","\u001b[K    100% |████████████████████████████████| 337kB 2.3MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.1.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.1.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras==2.1.5)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras==2.1.5)\n","Installing collected packages: Keras\n","  Found existing installation: Keras 2.0.0\n","    Uninstalling Keras-2.0.0:\n","      Successfully uninstalled Keras-2.0.0\n","Successfully installed Keras-2.1.5\n"],"name":"stdout"}]},{"metadata":{"id":"TmS1urFV_7C9","colab_type":"text"},"cell_type":"markdown","source":["\n","https://shaoanlu.wordpress.com/2017/08/17/senet-winner-of-imagenet-2017/"]},{"metadata":{"id":"hFmy5bWkHXZL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","import numpy as np\n","import warnings\n","\n","import keras\n","from keras.models import Model\n","\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Activation\n","from keras.layers import Input\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import ZeroPadding2D\n","from keras.layers import AveragePooling2D\n","from keras.layers import GlobalMaxPooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras.layers import BatchNormalization\n","from keras.preprocessing import image\n","from keras.utils import layer_utils\n","from keras.utils.data_utils import get_file\n","from keras import backend as K\n","from keras.applications.imagenet_utils import decode_predictions\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.applications.imagenet_utils import _obtain_input_shape\n","from keras.engine.topology import get_source_inputs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Eu5d3fJjHZOq","colab_type":"text"},"cell_type":"markdown","source":["# resnet画像分類の推定処理"]},{"metadata":{"id":"DnFzaL9oHdnn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["batch_size = 20\n","num_classes = 10\n","epochs = 100\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0fLwOHMzqEqt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[1:])\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z6My8SV-qEwL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model = Sequential()\n","model.add(ZeroPadding2D(padding=(3, 3), name='conv1_pad'))\n","model.add(Conv2D(64, (7, 7), strides=(2, 2), padding='valid', name='conv1', input_shape=x_train.shape[1:]))\n","model.add(BatchNormalization(axis=bn_axis, name='bn_conv1'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n","# Stage1\n","model.add(Conv2D(filters1, (1, 1), strides=strides, name=\"res1_blk1_branch2a\"))\n","model.add(BatchNormalization(axis=bn_axis, name=\"bn1_blk1_branch2a\"))\n","model.add(Activation('relu'))\n","model.add(Conv2D(filters1, (1, 1), strides=strides, name=\"res1_blk1_branch2b\"))\n","model.add(BatchNormalization(axis=bn_axis, name=\"bn1_blk1_branch2b\"))\n","model.add(Activation('relu'))\n","model.add(Conv2D(filters1, (1, 1), strides=strides, name=\"res1_blk1_branch2c\"))\n","model.add(BatchNormalization(axis=bn_axis, name=\"bn1_blk1_branch2c\"))\n","\n","shortcut = Sequential()\n","shortcut.add(Conv2D(filters1, (1, 1), strides=strides, name=\"res1_blk1_branch1\", input_shape=x_train.shape[1:]))\n","shortcut.add(BatchNormalization(axis=bn_axis, name=\"bn1_blk1_branch1\"))\n","model = Merge([shortcut, model], mode='add')\n","\n","\n","\n","\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), strides=strides,\n","               name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size, padding='same',\n","               name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","\n","    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n","                      name=conv_name_base + '1')(input_tensor)\n","    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n","\n","    x = keras.layers.add([x, shortcut])\n","    x = Activation('relu')(x)\n","    \n","\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=x_train.shape[1:]))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=x_train.shape[1:]))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JTGNnn3EqEzY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"UdqzpYiGHf8f","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def identity_block(input_tensor, kernel_size, filters, stage, block):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size,\n","               padding='same', name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","\n","    x = keras.layers.add([x, input_tensor])\n","    x = Activation('relu')(x)\n","    return x\n","\n","\n","def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), strides=strides,\n","               name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size, padding='same',\n","               name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","\n","    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n","                      name=conv_name_base + '1')(input_tensor)\n","    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n","\n","    x = keras.layers.add([x, shortcut])\n","    x = Activation('relu')(x)\n","    return x\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XLUNtKZSBbAe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def ResNet50(include_top=True, weights='imagenet',\n","             input_tensor=None, input_shape=None,\n","             pooling=None,\n","             classes=1000):\n","    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization), `imagenet` '\n","                         '(pre-training on ImageNet), '\n","                         'or the path to the weights file to be loaded.')\n","\n","    if weights == 'imagenet' and include_top and classes != 1000:\n","        raise ValueError('If using `weights` as imagenet with `include_top`'\n","                         ' as true, `classes` should be 1000')\n","\n","    # Determine proper input shape\n","    input_shape = _obtain_input_shape(input_shape,\n","                                      default_size=224,\n","                                      min_size=197,\n","                                      data_format=K.image_data_format(),\n","                                      include_top=include_top)\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","\n","    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n","    x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', name='conv1')(x)\n","    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n","\n","    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n","\n","    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n","\n","    if include_top:\n","        x = Flatten()(x)\n","        x = Dense(classes, activation='softmax', name='fc1000')(x)\n","    else:\n","        if pooling == 'avg':\n","            x = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            x = GlobalMaxPooling2D()(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","    # Create model.\n","    model = Model(inputs, x, name='resnet50')\n","\n","    # load weights\n","    if weights == 'imagenet':\n","        if include_top:\n","            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n","                                    WEIGHTS_PATH,\n","                                    cache_subdir='models',\n","                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n","        else:\n","            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","                                    WEIGHTS_PATH_NO_TOP,\n","                                    cache_subdir='models',\n","                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n","        model.load_weights(weights_path)\n","        if K.backend() == 'theano':\n","            layer_utils.convert_all_kernels_in_model(model)\n","            if include_top:\n","                maxpool = model.get_layer(name='avg_pool')\n","                shape = maxpool.output_shape[1:]\n","                dense = model.get_layer(name='fc1000')\n","                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n","\n","        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n","            warnings.warn('You are using the TensorFlow backend, yet you '\n","                          'are using the Theano '\n","                          'image data format convention '\n","                          '(`image_data_format=\"channels_first\"`). '\n","                          'For best performance, set '\n","                          '`image_data_format=\"channels_last\"` in '\n","                          'your Keras config '\n","                          'at ~/.keras/keras.json.')\n","    elif weights is not None:\n","        model.load_weights(weights)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ICeTsdZOHtMg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":4}],"base_uri":"https://localhost:8080/","height":158},"outputId":"985e36e4-8c73-46a9-f359-a9aa7edcc33c","executionInfo":{"status":"ok","timestamp":1522130697413,"user_tz":-540,"elapsed":9567,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["if __name__ == '__main__':\n","    model = ResNet50(include_top=True, weights='imagenet')\n","\n","    img_path = 'Horton-the-Elephant.png'\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    print('Input image shape:', x.shape)\n","\n","    preds = model.predict(x)\n","    print('Predicted:', decode_predictions(preds))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1062: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","Input image shape: (1, 224, 224, 3)\n","Downloading data from https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n","Predicted: [[('n02841315', 'binoculars', 0.107181594), ('n02504013', 'Indian_elephant', 0.089639105), ('n02412080', 'ram', 0.08123497), ('n02415577', 'bighorn', 0.03169293), ('n02124075', 'Egyptian_cat', 0.027336465)]]\n"],"name":"stdout"}]},{"metadata":{"id":"L7zo_Gr6ITwu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"BiRGr2k8EkUU","colab_type":"text"},"cell_type":"markdown","source":["# cifar10"]},{"metadata":{"id":"hTJsdGVSHnN0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def identity_block(input_tensor, kernel_size, filters, stage, block):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size,\n","               padding='same', name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","\n","    x = keras.layers.add([x, input_tensor])\n","    x = Activation('relu')(x)\n","    return x\n","\n","\n","def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), strides=strides,\n","               name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size, padding='same',\n","               name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","\n","    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n","                      name=conv_name_base + '1')(input_tensor)\n","    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n","\n","    x = keras.layers.add([x, shortcut])\n","    x = Activation('relu')(x)\n","    return x\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ABXIdiRSHnUI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def ResNet50(include_top=True, \n","             input_tensor=None, input_shape=None,\n","             pooling=None,\n","             classes=10):\n","    \n","    # Determine proper input shape\n","    input_shape = _obtain_input_shape(input_shape,\n","                                      default_size=32,\n","                                      min_size=197,\n","                                      data_format=K.image_data_format(),\n","                                      include_top=include_top)\n","\n","    print(input_shape)\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    \n","    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n","    x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', name='conv1')(x)\n","    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n","\n","#     x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n","#     x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n","#     x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n","#     x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n","\n","#     x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n","#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n","#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n","#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n","#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n","#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n","\n","#     x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n","#     x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n","#     x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n","\n","    if include_top:\n","        x = Flatten()(x)\n","        x = Dense(classes, activation='softmax', name='fc1000')(x)\n","    else:\n","        if pooling == 'avg':\n","            x = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            x = GlobalMaxPooling2D()(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","    # Create model.\n","    model = Model(inputs, x, name='resnet50')\n","    \n","\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0E81-5JYElwg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":2},{"item_id":3}],"base_uri":"https://localhost:8080/","height":672},"outputId":"642f5b97-5666-4cfd-e652-eb92cbbab0aa","executionInfo":{"status":"error","timestamp":1522134742002,"user_tz":-540,"elapsed":1412,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch > 180:\n","        lr *= 0.5e-3\n","    elif epoch > 160:\n","        lr *= 1e-3\n","    elif epoch > 120:\n","        lr *= 1e-2\n","    elif epoch > 80:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr\n","  \n","if __name__ == '__main__':\n","    from keras.datasets import cifar10\n","    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","    \n","    lr_scheduler = LearningRateScheduler(lr_schedule)\n","    \n","    model = ResNet50(include_top=True)\n","\n","#     img_path = 'Horton-the-Elephant.png'\n","#     img = image.load_img(img_path, target_size=(224, 224))\n","#     x = image.img_to_array(img)\n","#     x = np.expand_dims(x, axis=0)\n","#     x = preprocess_input(x)\n","#     print('Input image shape:', x.shape)\n","    model.compile(optimizer=Adam(lr=lr_schedule(0)), loss='categorical_crossentropy', metrics=['accuracy'])\n","    print(x_train.shape)\n","#     model.fit(x_train, y_train, batch_size=32)\n","    model.train_on_batch(x_train, y_train)\n","#     print('Predicted:', decode_predictions(preds))\n","\n"],"execution_count":75,"outputs":[{"output_type":"stream","text":["(32, 32, 3)\n","Learning rate:  0.001\n","(50000, 32, 32, 3)\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-75-33dd602be934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#     model.fit(x_train, y_train, batch_size=32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m#     print('Predicted:', decode_predictions(preds))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         \u001b[0;31m# Legacy support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'nb_epoch'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m             warnings.warn('The `nb_epoch` argument in `fit` '\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;31m# Instead, we store one array per batch seen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0;31m# and concatenate them upon returning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m             \u001b[0munconcatenated_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mx_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUser\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprovided\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0moutput_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mweight_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mused\u001b[0m \u001b[0mpurely\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m# Returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected fc1000 to have shape (None, 10) but got array with shape (50000, 1)"]}]},{"metadata":{"id":"oeNX9HILE-vv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}