{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/yusugomori/deeplearning-tensorflow-keras/blob/master/3/keras/01_logistic_regressioni_or_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s - loss: 0.4352     \n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s - loss: 0.4204     \n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s - loss: 0.4079     \n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s - loss: 0.3971     \n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s - loss: 0.3876     \n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s - loss: 0.3790     \n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s - loss: 0.3717     \n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s - loss: 0.3650     \n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s - loss: 0.3586     \n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s - loss: 0.3528     \n",
      "1/4 [======>.......................] - ETA: 0sclassified:\n",
      "[[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "output probability:\n",
      "[[ 0.53244859]\n",
      " [ 0.86008555]\n",
      " [ 0.68383926]\n",
      " [ 0.92110789]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "np.random.seed(0)  # 乱数シード\n",
    "\n",
    "'''\n",
    "モデル設定\n",
    "'''\n",
    "model = Sequential([\n",
    "    # Dense(input_dim=2, output_dim=1),  # Keras 1\n",
    "    Dense(input_dim=2, units=1),         # Keras 2\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
    "\n",
    "'''\n",
    "モデル学習\n",
    "'''\n",
    "# ORゲート\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0], [1], [1], [1]])\n",
    "\n",
    "# model.fit(X, Y, nb_epoch=200, batch_size=1)  # Keras 1\n",
    "model.fit(X, Y, epochs=10, batch_size=1)      # Keras 2\n",
    "\n",
    "'''\n",
    "学習結果の確認\n",
    "'''\n",
    "classes = model.predict_classes(X, batch_size=1)\n",
    "prob = model.predict_proba(X, batch_size=1)\n",
    "\n",
    "print('classified:')\n",
    "print(Y == classes)\n",
    "print()\n",
    "print('output probability:')\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2)\n",
      "(240,)\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 0s - loss: 0.6869 - acc: 0.5000     \n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 0s - loss: 0.6725 - acc: 0.5000     \n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 0s - loss: 0.6621 - acc: 0.5125     \n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 0s - loss: 0.6543 - acc: 0.5958     \n",
      "Epoch 5/10\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6428 - acc: 0.850 - 0s - loss: 0.6477 - acc: 0.7208     \n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 0s - loss: 0.6423 - acc: 0.7958     \n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 0s - loss: 0.6370 - acc: 0.7875     \n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 0s - loss: 0.6323 - acc: 0.8000     \n",
      "Epoch 9/10\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6188 - acc: 0.800 - 0s - loss: 0.6277 - acc: 0.8042     \n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 0s - loss: 0.6232 - acc: 0.8042     \n",
      "32/60 [===============>..............] - ETA: 0s[0.59703077475229904, 0.88333334128061936]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "'''\n",
    "データ生成\n",
    "'''\n",
    "N = 300\n",
    "X, y = datasets.make_moons(N, noise=0.3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "'''\n",
    "モデル生成\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "モデル学習\n",
    "'''\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=20)\n",
    "\n",
    "'''\n",
    "予測精度の評価\n",
    "'''\n",
    "loss_and_metrics = model.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 100, 3)\n",
      "(100, 10)\n",
      "Epoch 1/3\n",
      "100/100 [==============================] - 7s - loss: 2.3392     \n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 7s - loss: 2.3043     \n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 6s - loss: 2.2808     \n",
      "20/20 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 疑似データ生成\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "model = Sequential()\n",
    "# 入力: サイズが100x100で3チャンネルをもつ画像 -> (100, 100, 3) のテンソル\n",
    "# それぞれのlayerで3x3の畳み込み処理を適用している\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=3)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サイズ100、100で3チェンネルのバッチサイズ100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 100, 3)\n",
      "(100, 10)\n",
      "(100, 100, 3)\n",
      "(10,)\n",
      "Epoch 1/3\n",
      "100/100 [==============================] - 8s - loss: 72449.8689     \n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 7s - loss: 72453.7394     \n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 7s - loss: 72450.0303     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113e26470>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "data = np.arange(3000000).reshape((100,100,100,3))\n",
    "labels = np.arange(1000).reshape((100,10))\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(data[0].shape)\n",
    "print(labels[0].shape)\n",
    "\n",
    "model = Sequential()\n",
    "# 入力: サイズが100x100で3チャンネルをもつ画像 -> (100, 100, 3) のテンソル\n",
    "# それぞれのlayerで3x3の畳み込み処理を適用している\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(data, labels, batch_size=32, epochs=3)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サイズ256、256で3チェンネルのバッチサイズ100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 256, 256, 3)\n",
      "(100, 10)\n",
      "(256, 256, 3)\n",
      "(10,)\n",
      "Epoch 1/3\n",
      "100/100 [==============================] - 58s - loss: 72442.6194    \n",
      "Epoch 2/3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "data = np.arange(19660800).reshape((100,256,256,3))\n",
    "labels = np.arange(1000).reshape((100,10))\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(data[0].shape)\n",
    "print(labels[0].shape)\n",
    "\n",
    "model = Sequential()\n",
    "# 入力: サイズが100x100で3チャンネルをもつ画像 -> (100, 100, 3) のテンソル\n",
    "# それぞれのlayerで3x3の畳み込み処理を適用している\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(data, labels, batch_size=32, epochs=3)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4)\n",
      "(75, 4)\n",
      "4\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 0s - loss: 1.1894 - acc: 0.3467     \n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 0s - loss: 1.1372 - acc: 0.3467     \n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 0s - loss: 1.1013 - acc: 0.3467     \n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 0s - loss: 1.0796 - acc: 0.3600     \n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 0s - loss: 1.0657 - acc: 0.5067     \n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 0s - loss: 1.0589 - acc: 0.3867     \n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 0s - loss: 1.0523 - acc: 0.3733     \n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 0s - loss: 1.0473 - acc: 0.3733     \n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 0s - loss: 1.0440 - acc: 0.3733     \n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 0s - loss: 1.0404 - acc: 0.3733     \n",
      "Accuracy (train): 37.33%\n",
      "Accuracy (test) : 29.33%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "# irisデータのロード\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = np_utils.to_categorical(iris.target, num_classes=3)\n",
    "\n",
    "# シャッフルして訓練データとテストデータに分割\n",
    "n = iris.target.shape[0]\n",
    "indices = random.sample(range(n), n)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "n_train = int(n / 2)\n",
    "x_train = x[range(n_train)]\n",
    "y_train = y[range(n_train)]\n",
    "x_test = x[range(n_train, n)]\n",
    "y_test = y[range(n_train, n)]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x.shape[1],)\n",
    "\n",
    "\n",
    "# モデルの構築と学習\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(x.shape[1],), activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10, shuffle=True)\n",
    "\n",
    "# テスト結果表示\n",
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy (train): %.2f%%' % (scores[1]*100))\n",
    "scores = model.evaluate(x_test,  y_test,  verbose=0)\n",
    "print('Accuracy (test) : %.2f%%' % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
