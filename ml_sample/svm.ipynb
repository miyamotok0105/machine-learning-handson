{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cvxopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b836759a4dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Inference use Sum of (Kernel(x_train, xi) * weights * targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcvxopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolvers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mMIN_SUPPORT_VECTOR_MULTIPLIER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cvxopt'"
     ]
    }
   ],
   "source": [
    "#Inspired by http://tullo.ch/articles/svm-py/\n",
    "# Training: Calculate lag_range_multipliers (weights) and bias\n",
    "# Inference use Sum of (Kernel(x_train, xi) * weights * targets)\n",
    "import numpy as np\n",
    "import cvxopt.solvers\n",
    "\n",
    "MIN_SUPPORT_VECTOR_MULTIPLIER = 1e-5\n",
    "\n",
    "\n",
    "class SVMClassifier(object):\n",
    "    \n",
    "    def __init__(self, kernel, c):\n",
    "        self._kernel = kernel\n",
    "        self._c = c\n",
    "        \n",
    "    def predict(self, x, bias=None):\n",
    "        \"\"\"\n",
    "        Computes the SVM prediction on the given features x.\n",
    "        \"\"\"\n",
    "        if bias is None:\n",
    "            result = self._bias\n",
    "        else:\n",
    "            result = bias\n",
    "            \n",
    "        for z_i, x_i, y_i in zip(self._weights,\n",
    "                                 self._support_vectors,\n",
    "                                 self._support_vector_labels):\n",
    "            result += z_i * y_i * self._kernel(x_i, x)\n",
    "        return np.sign(result).item()\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Given the training features X with labels y, returns a SVM\n",
    "        predictor representing the trained SVM.\n",
    "        \"\"\"\n",
    "        lagrange_multipliers = self._compute_multipliers(X, y)\n",
    "        \n",
    "        support_vector_indices = \\\n",
    "            lagrange_multipliers > MIN_SUPPORT_VECTOR_MULTIPLIER\n",
    "\n",
    "        self._weights = lagrange_multipliers[support_vector_indices]\n",
    "        self._support_vectors = X[support_vector_indices]\n",
    "        self._support_vector_labels = y[support_vector_indices]\n",
    "\n",
    "        # http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/kernels.pdf\n",
    "        # bias = y_k - \\sum z_i y_i  K(x_k, x_i)\n",
    "        # Thus we can just predict an example with bias of zero, and\n",
    "        # compute error.\n",
    "        self._bias = np.mean(\n",
    "            [y_k - self.predict(x_k, bias=0.0)\n",
    "             for (y_k, x_k) in zip(self._support_vector_labels, self._support_vectors)])\n",
    " \n",
    "    def _gram_matrix(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        # TODO(tulloch) - vectorize\n",
    "        for i, x_i in enumerate(X):\n",
    "            for j, x_j in enumerate(X):\n",
    "                K[i, j] = self._kernel(x_i, x_j)\n",
    "        return K\n",
    "\n",
    "    def _compute_multipliers(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        K = self._gram_matrix(X)\n",
    "        # Solves\n",
    "        # min 1/2 x^T P x + q^T x\n",
    "        # s.t.\n",
    "        #  Gx \\coneleq h\n",
    "        #  Ax = b\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "        q = cvxopt.matrix(-1 * np.ones(n_samples))\n",
    "\n",
    "        # -a_i \\leq 0\n",
    "        # TODO(tulloch) - modify G, h so that we have a soft-margin classifier\n",
    "        G_std = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "        h_std = cvxopt.matrix(np.zeros(n_samples))\n",
    "\n",
    "        # a_i \\leq c\n",
    "        G_slack = cvxopt.matrix(np.diag(np.ones(n_samples)))\n",
    "        h_slack = cvxopt.matrix(np.ones(n_samples) * self._c)\n",
    "\n",
    "        G = cvxopt.matrix(np.vstack((G_std, G_slack)))\n",
    "        h = cvxopt.matrix(np.vstack((h_std, h_slack)))\n",
    "\n",
    "        A = cvxopt.matrix(y, (1, n_samples))\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        return np.ravel(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
