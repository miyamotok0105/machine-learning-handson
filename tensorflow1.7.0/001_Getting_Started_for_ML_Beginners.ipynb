{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001 Getting Started for ML Beginners.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "uJwIPcrZO5YW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#https://www.tensorflow.org/get_started/get_started_for_beginners"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-UyW_XS45v8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n0SReoIzZG_i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# データセット取得"
      ]
    },
    {
      "metadata": {
        "id": "MnQfArxhZfiS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.kerasはkerasのtensorflow実装。tf.keras.utils.get_fileはリモートCSV fileをローカルへ持ってくる"
      ]
    },
    {
      "metadata": {
        "id": "MIAAi7d9PS1x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "def maybe_download():\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path\n",
        "\n",
        "def load_data(y_name='Species'):\n",
        "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
        "    train_path, test_path = maybe_download()\n",
        "\n",
        "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "    train_x, train_y = train, train.pop(y_name)\n",
        "\n",
        "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "    test_x, test_y = test, test.pop(y_name)\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "\n",
        "def train_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def eval_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
        "    features=dict(features)\n",
        "    if labels is None:\n",
        "        # No labels, use only features.\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    # Batch the examples\n",
        "    assert batch_size is not None, \"batch_size must not be None\"\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# The remainder of this file contains a simple example of a csv parser,\n",
        "#     implemented using a the `Dataset` class.\n",
        "\n",
        "# `tf.parse_csv` sets the types of the outputs to match the examples given in\n",
        "#     the `record_defaults` argument.\n",
        "CSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
        "\n",
        "def _parse_line(line):\n",
        "    # Decode the line into its fields\n",
        "    fields = tf.decode_csv(line, record_defaults=CSV_TYPES)\n",
        "\n",
        "    # Pack the result into a dictionary\n",
        "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
        "\n",
        "    # Separate the label from the features\n",
        "    label = features.pop('Species')\n",
        "\n",
        "    return features, label\n",
        "\n",
        "\n",
        "def csv_input_fn(csv_path, batch_size):\n",
        "    # Create a dataset containing the text lines.\n",
        "    dataset = tf.data.TextLineDataset(csv_path).skip(1)\n",
        "\n",
        "    # Parse each line.\n",
        "    dataset = dataset.map(_parse_line)\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwbAeSXNO92r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5g1wWmkPN2P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d663c3a-a6dd-476b-c37c-3b99bd54ac5f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522402167121,
          "user_tz": -540,
          "elapsed": 652,
          "user": {
            "displayName": "宮本圭一郎",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100227668169464343249"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
        "parser.add_argument('--train_steps', default=1000, type=int,\n",
        "                    help='number of training steps')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--train_steps'], dest='train_steps', nargs=None, const=None, default=1000, type=<type 'int'>, choices=None, help='number of training steps', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "RSPEfo7VaqO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.estimator.DNNClassifierはあらかじめ用意された推定器"
      ]
    },
    {
      "metadata": {
        "id": "5EXvpNtPPYY-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1191
        },
        "outputId": "7ada49bf-40c7-476d-dfbb-f1b040b668f1",
        "executionInfo": {
          "status": "error",
          "timestamp": 1522402683254,
          "user_tz": -540,
          "elapsed": 3455,
          "user": {
            "displayName": "宮本圭一郎",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100227668169464343249"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def main(argv):\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "    # Fetch the data\n",
        "    (train_x, train_y), (test_x, test_y) = load_data()\n",
        "\n",
        "    # Feature columns describe how to use the input.\n",
        "    my_feature_columns = []\n",
        "    for key in train_x.keys():\n",
        "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "    # Build 2 hidden layer DNN with 10, 10 units respectively.\n",
        "    classifier = tf.estimator.DNNClassifier(\n",
        "        feature_columns=my_feature_columns,\n",
        "        # Two hidden layers of 10 nodes each.\n",
        "        hidden_units=[10, 10],\n",
        "        # The model must choose between 3 classes.\n",
        "        n_classes=3)\n",
        "\n",
        "    # Train the Model.\n",
        "    classifier.train(\n",
        "        input_fn=lambda:train_input_fn(train_x, train_y,\n",
        "                                                 args.batch_size),\n",
        "        steps=args.train_steps)\n",
        "\n",
        "    # Evaluate the model.\n",
        "    eval_result = classifier.evaluate(\n",
        "        input_fn=lambda:eval_input_fn(test_x, test_y,\n",
        "                                                args.batch_size))\n",
        "\n",
        "    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
        "\n",
        "    # Generate predictions from the model\n",
        "    expected = ['Setosa', 'Versicolor', 'Virginica']\n",
        "    predict_x = {\n",
        "        'SepalLength': [5.1, 5.9, 6.9],\n",
        "        'SepalWidth': [3.3, 3.0, 3.1],\n",
        "        'PetalLength': [1.7, 4.2, 5.4],\n",
        "        'PetalWidth': [0.5, 1.5, 2.1],\n",
        "    }\n",
        "\n",
        "    predictions = classifier.predict(\n",
        "        input_fn=lambda:eval_input_fn(predict_x,\n",
        "                                                labels=None,\n",
        "                                                batch_size=args.batch_size))\n",
        "\n",
        "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "\n",
        "    for pred_dict, expec in zip(predictions, expected):\n",
        "        class_id = pred_dict['class_ids'][0]\n",
        "        probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "        print(template.format(SPECIES[class_id],\n",
        "                              100 * probability, expec))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "    tf.app.run(main)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
            "\r16384/2194 [================================================================================================================================================================================================================================]16384/2194 [================================================================================================================================================================================================================================] - 0s 0us/step\n",
            "\n",
            "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
            "16384/573 [=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================]16384/573 [=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n",
            "\n",
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpxCeLQ0\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efff2232f50>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpxCeLQ0', '_save_summary_steps': 100}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpxCeLQ0/model.ckpt.\n",
            "INFO:tensorflow:loss = 173.5307, step = 1\n",
            "INFO:tensorflow:global_step/sec: 755.698\n",
            "INFO:tensorflow:loss = 15.920347, step = 101 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.15\n",
            "INFO:tensorflow:loss = 7.5815687, step = 201 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.082\n",
            "INFO:tensorflow:loss = 8.403783, step = 301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.129\n",
            "INFO:tensorflow:loss = 6.8480444, step = 401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.735\n",
            "INFO:tensorflow:loss = 5.7654448, step = 501 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.965\n",
            "INFO:tensorflow:loss = 4.643297, step = 601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.87\n",
            "INFO:tensorflow:loss = 4.784728, step = 701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.105\n",
            "INFO:tensorflow:loss = 2.8105724, step = 801 (0.099 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 965.391\n",
            "INFO:tensorflow:loss = 5.4522514, step = 901 (0.106 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpxCeLQ0/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 4.243033.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-03-30-09:38:02\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxCeLQ0/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-03-30-09:38:02\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.059844535, global_step = 1000, loss = 1.795336\n",
            "\n",
            "Test set accuracy: 0.967\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxCeLQ0/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "Prediction is \"Setosa\" (99.6%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Versicolor\" (99.5%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (98.8%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wRxXpnwTPbV6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}